Add event tracer.

This patch adds a event trace that hooks into various events
in the kernel. Although it can be used separately, it is mainly
to help other traces (wakeup and preempt off) with seeing various
events in the traces without having to enable the heavy mcount
hooks.

Signed-off-by: Steven Rostedt <srostedt@redhat.com>
---
 kernel/trace/Kconfig          |    8 
 kernel/trace/Makefile         |    1 
 kernel/trace/trace.c          |  220 ++++++++++++++++
 kernel/trace/trace.h          |   98 +++++++
 kernel/trace/trace_events.c   |  566 ++++++++++++++++++++++++++++++++++++++++++
 kernel/trace/trace_selftest.c |    7 
 6 files changed, 900 insertions(+)

Index: linux-2.6.26/kernel/trace/Kconfig
===================================================================
--- linux-2.6.26.orig/kernel/trace/Kconfig
+++ linux-2.6.26/kernel/trace/Kconfig
@@ -85,6 +85,14 @@ config SCHED_TRACER
 	  This tracer tracks the latency of the highest priority task
 	  to be scheduled in, starting from the point it has woken up.
 
+config EVENT_TRACER
+	bool "trace kernel events"
+	select CONTEXT_SWITCH_TRACER
+	help
+	  This option activates the event tracer of the latency_tracer.
+	  It activates markers through out the kernel for tracing.
+	  This option has a fairly low overhead when enabled.
+
 config CONTEXT_SWITCH_TRACER
 	bool "Trace process context switches"
 	depends on HAVE_FTRACE
Index: linux-2.6.26/kernel/trace/Makefile
===================================================================
--- linux-2.6.26.orig/kernel/trace/Makefile
+++ linux-2.6.26/kernel/trace/Makefile
@@ -18,5 +18,6 @@ obj-$(CONFIG_FTRACE) += trace_functions.
 obj-$(CONFIG_IRQSOFF_TRACER) += trace_irqsoff.o
 obj-$(CONFIG_PREEMPT_TRACER) += trace_irqsoff.o
 obj-$(CONFIG_SCHED_TRACER) += trace_sched_wakeup.o
+obj-$(CONFIG_EVENT_TRACER) += trace_events.o
 
 libftrace-y := ftrace.o
Index: linux-2.6.26/kernel/trace/trace.c
===================================================================
--- linux-2.6.26.orig/kernel/trace/trace.c
+++ linux-2.6.26/kernel/trace/trace.c
@@ -975,6 +975,126 @@ ftrace_special(unsigned long arg1, unsig
 	local_irq_restore(flags);
 }
 
+void tracing_event_irq(struct trace_array *tr,
+		       struct trace_array_cpu *data,
+		       unsigned long flags,
+		       unsigned long ip,
+		       int irq, int usermode,
+		       unsigned long retip)
+{
+	struct trace_entry *entry;
+
+	entry = tracing_get_trace_entry(tr, data);
+	tracing_generic_entry_update(entry, flags);
+	entry->type		= TRACE_IRQ;
+	entry->irq.ip		= ip;
+	entry->irq.irq		= irq;
+	entry->irq.ret_ip	= retip;
+	entry->irq.usermode	= usermode;
+}
+
+void tracing_event_fault(struct trace_array *tr,
+			 struct trace_array_cpu *data,
+			 unsigned long flags,
+			 unsigned long ip,
+			 unsigned long retip,
+			 unsigned long error_code,
+			 unsigned long address)
+{
+	struct trace_entry *entry;
+
+	entry = tracing_get_trace_entry(tr, data);
+	tracing_generic_entry_update(entry, flags);
+	entry->type		= TRACE_FAULT;
+	entry->fault.ip		= ip;
+	entry->fault.ret_ip	= retip;
+	entry->fault.errorcode	= error_code;
+	entry->fault.address	= address;
+}
+
+void tracing_event_timer_set(struct trace_array *tr,
+			     struct trace_array_cpu *data,
+			     unsigned long flags,
+			     unsigned long ip,
+			     ktime_t *expires, void *timer)
+{
+	struct trace_entry *entry;
+
+	entry = tracing_get_trace_entry(tr, data);
+	tracing_generic_entry_update(entry, flags);
+	entry->type		= TRACE_TIMER_SET;
+	entry->timer.ip		= ip;
+	entry->timer.expire	= *expires;
+	entry->timer.timer	= timer;
+}
+
+void tracing_event_timer_triggered(struct trace_array *tr,
+				   struct trace_array_cpu *data,
+				   unsigned long flags,
+				   unsigned long ip,
+				   ktime_t *expired, void *timer)
+{
+	struct trace_entry *entry;
+
+	entry = tracing_get_trace_entry(tr, data);
+	tracing_generic_entry_update(entry, flags);
+	entry->type		= TRACE_TIMER_TRIG;
+	entry->timer.ip		= ip;
+	entry->timer.expire	= *expired;
+	entry->timer.timer	= timer;
+}
+
+void tracing_event_timestamp(struct trace_array *tr,
+			     struct trace_array_cpu *data,
+			     unsigned long flags,
+			     unsigned long ip,
+			     ktime_t *now)
+{
+	struct trace_entry *entry;
+
+	entry = tracing_get_trace_entry(tr, data);
+	tracing_generic_entry_update(entry, flags);
+	entry->type		= TRACE_TIMESTAMP;
+	entry->timestamp.ip		= ip;
+	entry->timestamp.now		= *now;
+}
+
+void tracing_event_task_activate(struct trace_array *tr,
+				 struct trace_array_cpu *data,
+				 unsigned long flags,
+				 unsigned long ip,
+				 struct task_struct *p,
+				 int task_cpu)
+{
+	struct trace_entry *entry;
+
+	entry = tracing_get_trace_entry(tr, data);
+	tracing_generic_entry_update(entry, flags);
+	entry->type		= TRACE_TASK_ACT;
+	entry->task.ip		= ip;
+	entry->task.pid		= p->pid;
+	entry->task.prio	= p->prio;
+	entry->task.cpu		= task_cpu;
+}
+
+void tracing_event_task_deactivate(struct trace_array *tr,
+				   struct trace_array_cpu *data,
+				   unsigned long flags,
+				   unsigned long ip,
+				   struct task_struct *p,
+				   int task_cpu)
+{
+	struct trace_entry *entry;
+
+	entry = tracing_get_trace_entry(tr, data);
+	tracing_generic_entry_update(entry, flags);
+	entry->type		= TRACE_TASK_DEACT;
+	entry->task.ip		= ip;
+	entry->task.pid		= p->pid;
+	entry->task.prio	= p->prio;
+	entry->task.cpu		= task_cpu;
+}
+
 #ifdef CONFIG_FTRACE
 static void
 function_trace_call(unsigned long ip, unsigned long parent_ip)
@@ -1514,6 +1634,55 @@ print_lat_fmt(struct trace_iterator *ite
 		}
 		trace_seq_puts(s, "\n");
 		break;
+	case TRACE_IRQ:
+		seq_print_ip_sym(s, entry->irq.ip, sym_flags);
+		if (entry->irq.irq >= 0)
+			trace_seq_printf(s, " %d ", entry->irq.irq);
+		if (entry->irq.usermode)
+			trace_seq_puts(s, " (usermode)\n ");
+		else {
+			trace_seq_puts(s, " (");
+			seq_print_ip_sym(s, entry->irq.ret_ip, sym_flags);
+			trace_seq_puts(s, ")\n");
+		}
+		break;
+	case TRACE_FAULT:
+		seq_print_ip_sym(s, entry->fault.ip, sym_flags);
+		trace_seq_printf(s, " %lx ", entry->fault.errorcode);
+		trace_seq_puts(s, " (");
+		seq_print_ip_sym(s, entry->fault.ret_ip, sym_flags);
+		trace_seq_puts(s, ")");
+		trace_seq_printf(s, " [%lx]\n", entry->fault.address);
+		break;
+	case TRACE_TIMER_SET:
+		seq_print_ip_sym(s, entry->timer.ip, sym_flags);
+		trace_seq_printf(s, " (%Ld) (%p)\n",
+			   entry->timer.expire, entry->timer.timer);
+		break;
+	case TRACE_TIMER_TRIG:
+		seq_print_ip_sym(s, entry->timer.ip, sym_flags);
+		trace_seq_printf(s, " (%Ld) (%p)\n",
+			   entry->timer.expire, entry->timer.timer);
+		break;
+	case TRACE_TIMESTAMP:
+		seq_print_ip_sym(s, entry->timestamp.ip, sym_flags);
+		trace_seq_printf(s, " (%Ld)\n",
+			   entry->timestamp.now.tv64);
+		break;
+	case TRACE_TASK_ACT:
+		seq_print_ip_sym(s, entry->task.ip, sym_flags);
+		comm = trace_find_cmdline(entry->task.pid);
+		trace_seq_printf(s, " %s %d %d [%d]\n",
+			   comm, entry->task.pid,
+			   entry->task.prio, entry->task.cpu);
+		break;
+	case TRACE_TASK_DEACT:
+		seq_print_ip_sym(s, entry->task.ip, sym_flags);
+		comm = trace_find_cmdline(entry->task.pid);
+		trace_seq_printf(s, " %s %d %d [%d]\n",
+			   comm, entry->task.pid,
+			   entry->task.prio, entry->task.cpu);
+		break;
 	default:
 		trace_seq_printf(s, "Unknown type %d\n", entry->type);
 	}
@@ -1614,6 +1783,57 @@ static int print_trace_fmt(struct trace_
 		if (!ret)
 			return 0;
 		break;
+	case TRACE_IRQ:
+		seq_print_ip_sym(s, entry->irq.ip, sym_flags);
+		if (entry->irq.irq >= 0)
+			trace_seq_printf(s, " %d ", entry->irq.irq);
+		if (entry->irq.usermode)
+			trace_seq_puts(s, " (usermode)\n ");
+		else {
+			trace_seq_puts(s, " (");
+			seq_print_ip_sym(s, entry->irq.ret_ip, sym_flags);
+			trace_seq_puts(s, ")\n");
+		}
+		break;
+	case TRACE_FAULT:
+		seq_print_ip_sym(s, entry->fault.ip, sym_flags);
+		trace_seq_printf(s, " %lx ", entry->fault.errorcode);
+		trace_seq_puts(s, " (");
+		seq_print_ip_sym(s, entry->fault.ret_ip, sym_flags);
+		trace_seq_puts(s, ")");
+		trace_seq_printf(s, " [%lx]\n", entry->fault.address);
+		break;
+	case TRACE_TIMER_SET:
+		seq_print_ip_sym(s, entry->timer.ip, sym_flags);
+		trace_seq_printf(s, " (%Ld) (%p)\n",
+			   entry->timer.expire, entry->timer.timer);
+		break;
+	case TRACE_TIMER_TRIG:
+		seq_print_ip_sym(s, entry->timer.ip, sym_flags);
+		trace_seq_printf(s, " (%Ld) (%p)\n",
+			   entry->timer.expire, entry->timer.timer);
+		break;
+	case TRACE_TIMESTAMP:
+		seq_print_ip_sym(s, entry->timestamp.ip, sym_flags);
+		trace_seq_printf(s, " (%Ld)\n",
+			   entry->timestamp.now.tv64);
+		break;
+	case TRACE_TASK_ACT:
+		seq_print_ip_sym(s, entry->task.ip, sym_flags);
+		comm = trace_find_cmdline(entry->task.pid);
+		trace_seq_printf(s, " %s %d %d [%d]\n",
+			   comm, entry->task.pid,
+			   entry->task.prio, entry->task.cpu);
+		break;
+	case TRACE_TASK_DEACT:
+		seq_print_ip_sym(s, entry->task.ip, sym_flags);
+		comm = trace_find_cmdline(entry->task.pid);
+		trace_seq_printf(s, " %s %d %d [%d]\n",
+			   comm, entry->task.pid,
+			   entry->task.prio, entry->task.cpu);
+		break;
+	default:
+		trace_seq_printf(s, "Unknown type %d\n", entry->type);
 	}
 	return 1;
 }
Index: linux-2.6.26/kernel/trace/trace.h
===================================================================
--- linux-2.6.26.orig/kernel/trace/trace.h
+++ linux-2.6.26/kernel/trace/trace.h
@@ -14,6 +14,13 @@ enum trace_type {
 	TRACE_WAKE,
 	TRACE_STACK,
 	TRACE_SPECIAL,
+	TRACE_IRQ,
+	TRACE_FAULT,
+	TRACE_TIMER_SET,
+	TRACE_TIMER_TRIG,
+	TRACE_TIMESTAMP,
+	TRACE_TASK_ACT,
+	TRACE_TASK_DEACT,
 
 	__TRACE_LAST_TYPE
 };
@@ -47,6 +54,45 @@ struct special_entry {
 	unsigned long		arg3;
 };
 
+struct irq_entry {
+	unsigned long		ip;
+	unsigned long		ret_ip;
+	unsigned		irq;
+	unsigned		usermode;
+};
+
+struct fault_entry {
+	unsigned long		ip;
+	unsigned long		ret_ip;
+	unsigned long		errorcode;
+	unsigned long		address;
+};
+
+struct timer_entry {
+	unsigned long		ip;
+	ktime_t			expire;
+	void			*timer;
+};
+
+struct timestamp_entry {
+	unsigned long		ip;
+	ktime_t			now;
+};
+
+struct task_entry {
+	unsigned long		ip;
+	pid_t			pid;
+	unsigned		prio;
+	int			cpu;
+};
+
+struct wakeup_entry {
+	unsigned long		ip;
+	pid_t			pid;
+	unsigned		prio;
+	unsigned		curr_prio;
+};
+
 /*
  * Stack-trace entry:
  */
@@ -75,6 +121,12 @@ struct trace_entry {
 		struct ctx_switch_entry		ctx;
 		struct special_entry		special;
 		struct stack_entry		stack;
+		struct irq_entry		irq;
+		struct fault_entry		fault;
+		struct timer_entry		timer;
+		struct timestamp_entry		timestamp;
+		struct task_entry		task;
+		struct wakeup_entry		wakeup;
 	};
 };
 
@@ -215,6 +267,52 @@ void trace_function(struct trace_array *
 		    unsigned long ip,
 		    unsigned long parent_ip,
 		    unsigned long flags);
+void tracing_event_irq(struct trace_array *tr,
+		       struct trace_array_cpu *data,
+		       unsigned long flags,
+		       unsigned long ip,
+		       int irq, int usermode,
+		       unsigned long retip);
+void tracing_event_fault(struct trace_array *tr,
+			 struct trace_array_cpu *data,
+			 unsigned long flags,
+			 unsigned long ip,
+			 unsigned long retip,
+			 unsigned long error_code,
+			 unsigned long address);
+void tracing_event_timer_set(struct trace_array *tr,
+			     struct trace_array_cpu *data,
+			     unsigned long flags,
+			     unsigned long ip,
+			     ktime_t *expires, void *timer);
+void tracing_event_timer_triggered(struct trace_array *tr,
+				   struct trace_array_cpu *data,
+				   unsigned long flags,
+				   unsigned long ip,
+				   ktime_t *expired, void *timer);
+void tracing_event_timestamp(struct trace_array *tr,
+			     struct trace_array_cpu *data,
+			     unsigned long flags,
+			     unsigned long ip,
+			     ktime_t *now);
+void tracing_event_task_activate(struct trace_array *tr,
+				 struct trace_array_cpu *data,
+				 unsigned long flags,
+				 unsigned long ip,
+				 struct task_struct *p,
+				 int cpu);
+void tracing_event_task_deactivate(struct trace_array *tr,
+				   struct trace_array_cpu *data,
+				   unsigned long flags,
+				   unsigned long ip,
+				   struct task_struct *p,
+				   int cpu);
+void tracing_event_wakeup(struct trace_array *tr,
+			  struct trace_array_cpu *data,
+			  unsigned long flags,
+			  unsigned long ip,
+			  pid_t pid, int prio,
+			  int curr_prio);
 
 void tracing_start_cmdline_record(void);
 void tracing_stop_cmdline_record(void);
Index: linux-2.6.26/kernel/trace/trace_events.c
===================================================================
--- /dev/null
+++ linux-2.6.26/kernel/trace/trace_events.c
@@ -0,0 +1,566 @@
+/*
+ * trace task events
+ *
+ * Copyright (C) 2007 Steven Rostedt <srostedt@redhat.com>
+ *
+ * Based on code from the latency_tracer, that is:
+ *
+ *  Copyright (C) 2004-2006 Ingo Molnar
+ *  Copyright (C) 2004 William Lee Irwin III
+ */
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/debugfs.h>
+#include <linux/kallsyms.h>
+#include <linux/uaccess.h>
+#include <linux/ftrace.h>
+
+#include "trace.h"
+
+static struct trace_array __read_mostly	*events_trace;
+static int __read_mostly	tracer_enabled;
+static atomic_t			event_ref;
+
+static void event_reset(struct trace_array *tr)
+{
+	struct trace_array_cpu *data;
+	int cpu;
+
+	for_each_possible_cpu(cpu) {
+		data = tr->data[cpu];
+		tracing_reset(data);
+	}
+
+	tr->time_start = ftrace_now(raw_smp_processor_id());
+}
+
+#define getarg(arg, ap) arg = va_arg(ap, typeof(arg));
+
+static void
+event_irq_callback(void *probe_data, void *call_data,
+		   const char *format, va_list *args)
+{
+	struct trace_array *tr = probe_data;
+	struct trace_array_cpu *data;
+	unsigned long ip, flags;
+	int irq, user, cpu;
+	long disable;
+
+	if (!tracer_enabled)
+		return;
+
+	getarg(irq, *args);
+	getarg(user, *args);
+	getarg(ip, *args);
+
+	/* interrupts should be off, we are in an interrupt */
+	cpu = smp_processor_id();
+	data = tr->data[cpu];
+
+	disable = atomic_inc_return(&data->disabled);
+	if (disable != 1)
+		goto out;
+
+	local_save_flags(flags);
+	tracing_event_irq(tr, data, flags, CALLER_ADDR1, irq, user, ip);
+
+ out:
+	atomic_dec(&data->disabled);
+}
+
+static void
+event_fault_callback(void *probe_data, void *call_data,
+		     const char *format, va_list *args)
+{
+	struct trace_array *tr = probe_data;
+	struct trace_array_cpu *data;
+	unsigned long ip, flags, error, addr;
+	long disable;
+	int cpu;
+
+	if (!tracer_enabled)
+		return;
+
+	getarg(ip, *args);
+	getarg(error, *args);
+	getarg(addr, *args);
+
+	preempt_disable_notrace();
+	cpu = smp_processor_id();
+	data = tr->data[cpu];
+
+	disable = atomic_inc_return(&data->disabled);
+	if (disable != 1)
+		goto out;
+
+	local_save_flags(flags);
+	tracing_event_fault(tr, data, flags, CALLER_ADDR1, ip, error, addr);
+
+ out:
+	atomic_dec(&data->disabled);
+	preempt_enable_notrace();
+}
+
+static void
+event_timer_set_callback(void *probe_data, void *call_data,
+			 const char *format, va_list *args)
+{
+	struct trace_array *tr = probe_data;
+	struct trace_array_cpu *data;
+	unsigned long flags;
+	ktime_t *expires;
+	void *timer;
+	long disable;
+	int cpu;
+
+	if (!tracer_enabled)
+		return;
+
+	getarg(expires, *args);
+	getarg(timer, *args);
+
+	/* interrupts should be off, we are in an interrupt */
+	cpu = smp_processor_id();
+	data = tr->data[cpu];
+
+	disable = atomic_inc_return(&data->disabled);
+	if (disable != 1)
+		goto out;
+
+	local_save_flags(flags);
+	tracing_event_timer_set(tr, data, flags, CALLER_ADDR1, expires, timer);
+
+ out:
+	atomic_dec(&data->disabled);
+}
+
+static void
+event_timer_triggered_callback(void *probe_data, void *call_data,
+			       const char *format, va_list *args)
+{
+	struct trace_array *tr = probe_data;
+	struct trace_array_cpu *data;
+	unsigned long flags;
+	ktime_t *expired;
+	void *timer;
+	long disable;
+	int cpu;
+
+	if (!tracer_enabled)
+		return;
+
+	getarg(expired, *args);
+	getarg(timer, *args);
+
+	/* interrupts should be off, we are in an interrupt */
+	cpu = smp_processor_id();
+	data = tr->data[cpu];
+
+	disable = atomic_inc_return(&data->disabled);
+	if (disable != 1)
+		goto out;
+
+	local_save_flags(flags);
+	tracing_event_timer_triggered(tr, data, flags, CALLER_ADDR1, expired, timer);
+
+ out:
+	atomic_dec(&data->disabled);
+}
+
+static void
+event_hrtimer_callback(void *probe_data, void *call_data,
+		       const char *format, va_list *args)
+{
+	struct trace_array *tr = probe_data;
+	struct trace_array_cpu *data;
+	unsigned long flags;
+	ktime_t *now;
+	long disable;
+	int cpu;
+
+	if (!tracer_enabled)
+		return;
+
+	getarg(now, *args);
+
+	/* interrupts should be off, we are in an interrupt */
+	cpu = smp_processor_id();
+	data = tr->data[cpu];
+
+	disable = atomic_inc_return(&data->disabled);
+	if (disable != 1)
+		goto out;
+
+	local_save_flags(flags);
+	tracing_event_timestamp(tr, data, flags, CALLER_ADDR1, now);
+
+ out:
+	atomic_dec(&data->disabled);
+}
+
+static void
+event_task_activate_callback(void *probe_data, void *call_data,
+			     const char *format, va_list *args)
+{
+	struct trace_array *tr = probe_data;
+	struct trace_array_cpu *data;
+	unsigned long flags;
+	struct task_struct *p;
+	long disable;
+	int cpu, rqcpu;
+
+	if (!tracer_enabled)
+		return;
+
+	getarg(p, *args);
+	getarg(rqcpu, *args);
+
+	/* interrupts should be off, we are in an interrupt */
+	cpu = smp_processor_id();
+	data = tr->data[cpu];
+
+	disable = atomic_inc_return(&data->disabled);
+	if (disable != 1)
+		goto out;
+
+	local_save_flags(flags);
+	tracing_event_task_activate(tr, data, flags, CALLER_ADDR1, p, rqcpu);
+
+ out:
+	atomic_dec(&data->disabled);
+}
+
+static void
+event_task_deactivate_callback(void *probe_data, void *call_data,
+			       const char *format, va_list *args)
+{
+	struct trace_array *tr = probe_data;
+	struct trace_array_cpu *data;
+	unsigned long flags;
+	struct task_struct *p;
+	long disable;
+	int cpu, rqcpu;
+
+	if (!tracer_enabled)
+		return;
+
+	getarg(p, *args);
+	getarg(rqcpu, *args);
+
+	/* interrupts should be off, we are in an interrupt */
+	cpu = smp_processor_id();
+	data = tr->data[cpu];
+
+	disable = atomic_inc_return(&data->disabled);
+	if (disable != 1)
+		goto out;
+
+	local_save_flags(flags);
+	tracing_event_task_deactivate(tr, data, flags, CALLER_ADDR1, p, rqcpu);
+
+ out:
+	atomic_dec(&data->disabled);
+}
+
+static void
+event_wakeup_callback(void *probe_data, void *call_data,
+		      const char *format, va_list *args)
+{
+	struct trace_array *tr = probe_data;
+	struct trace_array_cpu *data;
+	unsigned long flags;
+	struct task_struct *wakee, *curr;
+	long disable, ignore2;
+	void *ignore3;
+	int ignore1;
+	int cpu;
+
+	if (!tracer_enabled)
+		return;
+
+	getarg(ignore1, *args);
+	getarg(ignore2, *args);
+	getarg(ignore3, *args);
+
+	getarg(wakee, *args);
+	getarg(curr, *args);
+
+	/* interrupts should be disabled */
+	cpu = smp_processor_id();
+	data = tr->data[cpu];
+
+	disable = atomic_inc_return(&data->disabled);
+	if (unlikely(disable != 1))
+		goto out;
+
+	local_save_flags(flags);
+	/* record process's command line */
+	tracing_record_cmdline(wakee);
+	tracing_record_cmdline(curr);
+
+	tracing_sched_wakeup_trace(tr, data, wakee, curr, flags);
+
+ out:
+	atomic_dec(&data->disabled);
+}
+static void
+event_ctx_callback(void *probe_data, void *call_data,
+		   const char *format, va_list *args)
+{
+	struct trace_array *tr = probe_data;
+	struct trace_array_cpu *data;
+	unsigned long flags;
+	struct task_struct *prev;
+	struct task_struct *next;
+	long disable, ignore2;
+	void *ignore3;
+	int ignore1;
+	int cpu;
+
+	if (!tracer_enabled)
+		return;
+
+	/* skip prev_pid %d next_pid %d prev_state %ld */
+	getarg(ignore1, *args);
+	getarg(ignore1, *args);
+	getarg(ignore2, *args);
+	getarg(ignore3, *args);
+
+	prev = va_arg(*args, typeof(prev));
+	next = va_arg(*args, typeof(next));
+
+	tracing_record_cmdline(prev);
+	tracing_record_cmdline(next);
+
+	/* interrupts should be disabled */
+	cpu = smp_processor_id();
+	data = tr->data[cpu];
+	disable = atomic_inc_return(&data->disabled);
+
+	if (likely(disable != 1))
+		goto out;
+
+	local_save_flags(flags);
+	tracing_sched_switch_trace(tr, data, prev, next, flags);
+ out:
+	atomic_dec(&data->disabled);
+}
+
+static int event_register_marker(const char *name, const char *format,
+				 marker_probe_func *probe, void *data)
+{
+	int ret;
+
+	ret = marker_probe_register(name, format, probe, data);
+	if (ret) {
+		pr_info("event trace: Couldn't add marker"
+			" probe to %s\n", name);
+		return ret;
+	}
+
+	return 0;
+}
+
+static void event_tracer_register(struct trace_array *tr)
+{
+	int ret;
+
+	ret = event_register_marker("ftrace_event_irq", "%d %d %ld",
+				    event_irq_callback, tr);
+	if (ret)
+		return;
+
+	ret = event_register_marker("ftrace_event_fault", "%ld %ld %ld",
+				    event_fault_callback, tr);
+	if (ret)
+		goto out1;
+
+	ret = event_register_marker("ftrace_event_timer_set", "%p %p",
+				    event_timer_set_callback, tr);
+	if (ret)
+		goto out2;
+
+	ret = event_register_marker("ftrace_event_timer_triggered", "%p %p",
+				    event_timer_triggered_callback, tr);
+	if (ret)
+		goto out3;
+
+	ret = event_register_marker("ftrace_event_hrtimer", "%p",
+				    event_hrtimer_callback, tr);
+	if (ret)
+		goto out4;
+
+	ret = event_register_marker("ftrace_event_task_activate", "%p %d",
+				    event_task_activate_callback, tr);
+	if (ret)
+		goto out5;
+
+	ret = event_register_marker("ftrace_event_task_deactivate", "%p %d",
+				    event_task_deactivate_callback, tr);
+	if (ret)
+		goto out6;
+
+	ret = event_register_marker("kernel_sched_wakeup",
+				    "pid %d state %ld ## rq %p task %p rq->curr %p",
+				    event_wakeup_callback, tr);
+	if (ret)
+		goto out7;
+
+	ret = event_register_marker("kernel_sched_wakeup_new",
+				    "pid %d state %ld ## rq %p task %p rq->curr %p",
+				    event_wakeup_callback, tr);
+	if (ret)
+		goto out8;
+
+	ret = event_register_marker("kernel_sched_schedule",
+				    "prev_pid %d next_pid %d prev_state %ld "
+				    "## rq %p prev %p next %p",
+				    event_ctx_callback, tr);
+	if (ret)
+		goto out9;
+
+	return;
+
+ out9:
+	marker_probe_unregister("kernel_sched_wakeup_new",
+				event_wakeup_callback, tr);
+ out8:
+	marker_probe_unregister("kernel_sched_wakeup",
+				event_wakeup_callback, tr);
+ out7:
+	marker_probe_unregister("ftrace_event_task_deactivate",
+				event_task_deactivate_callback, tr);
+ out6:
+	marker_probe_unregister("ftrace_event_task_activate",
+				event_task_activate_callback, tr);
+ out5:
+	marker_probe_unregister("ftrace_event_hrtimer",
+				event_hrtimer_callback, tr);
+ out4:
+	marker_probe_unregister("ftrace_event_timer_triggered",
+				event_timer_triggered_callback, tr);
+ out3:
+	marker_probe_unregister("ftrace_event_timer_set",
+				event_timer_set_callback, tr);
+ out2:
+	marker_probe_unregister("ftrace_event_fault",
+				event_fault_callback, tr);
+ out1:
+	marker_probe_unregister("ftrace_event_irq",
+				event_irq_callback, tr);
+}
+
+static void event_tracer_unregister(struct trace_array *tr)
+{
+	marker_probe_unregister("kernel_sched_schedule",
+				event_ctx_callback, tr);
+	marker_probe_unregister("kernel_sched_wakeup_new",
+				event_wakeup_callback, tr);
+	marker_probe_unregister("kernel_sched_wakeup",
+				event_wakeup_callback, tr);
+	marker_probe_unregister("ftrace_event_task_deactivate",
+			      event_task_deactivate_callback, tr);
+	marker_probe_unregister("ftrace_event_task_activate",
+				event_task_activate_callback, tr);
+	marker_probe_unregister("ftrace_event_hrtimer",
+				event_hrtimer_callback, tr);
+	marker_probe_unregister("ftrace_event_timer_triggered",
+				event_timer_triggered_callback, tr);
+	marker_probe_unregister("ftrace_event_timer_set",
+				event_timer_set_callback, tr);
+	marker_probe_unregister("ftrace_event_fault",
+				event_fault_callback, tr);
+	marker_probe_unregister("ftrace_event_irq",
+				event_irq_callback, tr);
+}
+
+void trace_event_register(struct trace_array *tr)
+{
+	long ref;
+
+	ref = atomic_inc_return(&event_ref);
+	if (ref == 1)
+		event_tracer_register(tr);
+}
+
+void trace_event_unregister(struct trace_array *tr)
+{
+	long ref;
+
+	ref = atomic_dec_and_test(&event_ref);
+	if (ref)
+		event_tracer_unregister(tr);
+}
+
+static void start_event_trace(struct trace_array *tr)
+{
+	event_reset(tr);
+	trace_event_register(tr);
+	tracing_start_function_trace();
+	tracer_enabled = 1;
+}
+
+static void stop_event_trace(struct trace_array *tr)
+{
+	tracer_enabled = 0;
+	tracing_stop_function_trace();
+	trace_event_unregister(tr);
+}
+
+static void event_trace_init(struct trace_array *tr)
+{
+	events_trace = tr;
+
+	if (tr->ctrl)
+		start_event_trace(tr);
+}
+
+static void event_trace_reset(struct trace_array *tr)
+{
+	if (tr->ctrl)
+		stop_event_trace(tr);
+}
+
+static void event_trace_ctrl_update(struct trace_array *tr)
+{
+	if (tr->ctrl)
+		start_event_trace(tr);
+	else
+		stop_event_trace(tr);
+}
+
+static void event_trace_open(struct trace_iterator *iter)
+{
+	/* stop the trace while dumping */
+	if (iter->tr->ctrl)
+		tracer_enabled = 0;
+}
+
+static void event_trace_close(struct trace_iterator *iter)
+{
+	if (iter->tr->ctrl)
+		tracer_enabled = 1;
+}
+
+static struct tracer event_trace __read_mostly =
+{
+	.name = "events",
+	.init = event_trace_init,
+	.reset = event_trace_reset,
+	.open = event_trace_open,
+	.close = event_trace_close,
+	.ctrl_update = event_trace_ctrl_update,
+};
+
+__init static int init_event_trace(void)
+{
+	int ret;
+
+	ret = register_tracer(&event_trace);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+device_initcall(init_event_trace);
Index: linux-2.6.26/kernel/trace/trace_selftest.c
===================================================================
--- linux-2.6.26.orig/kernel/trace/trace_selftest.c
+++ linux-2.6.26/kernel/trace/trace_selftest.c
@@ -11,6 +11,13 @@ static inline int trace_valid_entry(stru
 	case TRACE_WAKE:
 	case TRACE_STACK:
 	case TRACE_SPECIAL:
+	case TRACE_IRQ:
+	case TRACE_FAULT:
+	case TRACE_TIMER_SET:
+	case TRACE_TIMER_TRIG:
+	case TRACE_TIMESTAMP:
+	case TRACE_TASK_ACT:
+	case TRACE_TASK_DEACT:
 		return 1;
 	}
 	return 0;
