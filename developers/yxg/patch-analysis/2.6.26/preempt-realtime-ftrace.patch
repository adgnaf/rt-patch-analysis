---
 kernel/trace/ftrace.c             |    4 ++--
 kernel/trace/trace.c              |    2 +-
 kernel/trace/trace_hist.c         |    2 +-
 kernel/trace/trace_irqsoff.c      |    2 +-
 kernel/trace/trace_sched_wakeup.c |    2 +-
 5 files changed, 6 insertions(+), 6 deletions(-)

Index: linux-2.6.26/kernel/trace/ftrace.c
===================================================================
--- linux-2.6.26.orig/kernel/trace/ftrace.c
+++ linux-2.6.26/kernel/trace/ftrace.c
@@ -42,7 +42,7 @@ static int last_ftrace_enabled;
  */
 static int ftrace_disabled __read_mostly;
 
-static DEFINE_SPINLOCK(ftrace_lock);
+static DEFINE_RAW_SPINLOCK(ftrace_lock);
 static DEFINE_MUTEX(ftrace_sysctl_lock);
 
 static struct ftrace_ops ftrace_list_end __read_mostly =
@@ -194,7 +194,7 @@ static struct hlist_head ftrace_hash[FTR
 
 static DEFINE_PER_CPU(int, ftrace_shutdown_disable_cpu);
 
-static DEFINE_SPINLOCK(ftrace_shutdown_lock);
+static DEFINE_RAW_SPINLOCK(ftrace_shutdown_lock);
 static DEFINE_MUTEX(ftraced_lock);
 static DEFINE_MUTEX(ftrace_regex_lock);
 
Index: linux-2.6.26/kernel/trace/trace.c
===================================================================
--- linux-2.6.26.orig/kernel/trace/trace.c
+++ linux-2.6.26/kernel/trace/trace.c
@@ -669,7 +669,7 @@ static unsigned map_pid_to_cmdline[PID_M
 static unsigned map_cmdline_to_pid[SAVED_CMDLINES];
 static char saved_cmdlines[SAVED_CMDLINES][TASK_COMM_LEN];
 static int cmdline_idx;
-static DEFINE_SPINLOCK(trace_cmdline_lock);
+static DEFINE_RAW_SPINLOCK(trace_cmdline_lock);
 
 /* temporary disable recording */
 atomic_t trace_record_cmdline_disabled __read_mostly;
Index: linux-2.6.26/kernel/trace/trace_hist.c
===================================================================
--- linux-2.6.26.orig/kernel/trace/trace_hist.c
+++ linux-2.6.26/kernel/trace/trace_hist.c
@@ -412,7 +412,7 @@ int tracing_wakeup_hist __read_mostly = 
 static unsigned wakeup_prio = (unsigned)-1 ;
 static struct task_struct *wakeup_task;
 static cycle_t wakeup_start;
-static DEFINE_SPINLOCK(wakeup_lock);
+static DEFINE_RAW_SPINLOCK(wakeup_lock);
 
 notrace void tracing_hist_wakeup_start(struct task_struct *p,
 				       struct task_struct *curr)
Index: linux-2.6.26/kernel/trace/trace_irqsoff.c
===================================================================
--- linux-2.6.26.orig/kernel/trace/trace_irqsoff.c
+++ linux-2.6.26/kernel/trace/trace_irqsoff.c
@@ -24,7 +24,7 @@ static int				tracer_enabled __read_most
 
 static DEFINE_PER_CPU(int, tracing_cpu);
 
-static DEFINE_SPINLOCK(max_trace_lock);
+static DEFINE_RAW_SPINLOCK(max_trace_lock);
 
 enum {
 	TRACER_IRQS_OFF		= (1 << 1),
Index: linux-2.6.26/kernel/trace/trace_sched_wakeup.c
===================================================================
--- linux-2.6.26.orig/kernel/trace/trace_sched_wakeup.c
+++ linux-2.6.26/kernel/trace/trace_sched_wakeup.c
@@ -26,7 +26,7 @@ static struct task_struct	*wakeup_task;
 static int			wakeup_cpu;
 static unsigned			wakeup_prio = -1;
 
-static DEFINE_SPINLOCK(wakeup_lock);
+static DEFINE_RAW_SPINLOCK(wakeup_lock);
 
 static void __wakeup_reset(struct trace_array *tr);
 
