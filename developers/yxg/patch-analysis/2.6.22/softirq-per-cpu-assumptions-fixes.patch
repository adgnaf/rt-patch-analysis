---
 kernel/hrtimer.c |   38 +++++++++++++++++++++-----------------
 kernel/sched.c   |    2 +-
 kernel/softirq.c |    5 +++--
 kernel/timer.c   |    2 +-
 4 files changed, 26 insertions(+), 21 deletions(-)

Index: linux-rt.q/kernel/hrtimer.c
===================================================================
--- linux-rt.q.orig/kernel/hrtimer.c
+++ linux-rt.q/kernel/hrtimer.c
@@ -347,9 +347,9 @@ static inline int hrtimer_is_hres_enable
 /*
  * Is the high resolution mode active ?
  */
-static inline int hrtimer_hres_active(void)
+static inline int hrtimer_hres_active(struct hrtimer_cpu_base *cpu_base)
 {
-	return __get_cpu_var(hrtimer_bases).hres_active;
+	return cpu_base->hres_active;
 }
 
 /*
@@ -426,11 +426,12 @@ static int hrtimer_reprogram(struct hrti
  */
 static void retrigger_next_event(void *arg)
 {
-	struct hrtimer_cpu_base *base;
+	struct hrtimer_cpu_base *base = &__get_cpu_var(hrtimer_bases);
+
 	struct timespec realtime_offset;
 	unsigned long seq;
 
-	if (!hrtimer_hres_active())
+	if (!hrtimer_hres_active(base))
 		return;
 
 	do {
@@ -440,8 +441,6 @@ static void retrigger_next_event(void *a
 					-wall_to_monotonic.tv_nsec);
 	} while (read_seqretry(&xtime_lock, seq));
 
-	base = &__get_cpu_var(hrtimer_bases);
-
 	/* Adjust CLOCK_REALTIME offset */
 	spin_lock(&base->lock);
 	base->clock_base[CLOCK_REALTIME].offset =
@@ -563,10 +562,8 @@ static inline int hrtimer_enqueue_reprog
 /*
  * Switch to high resolution mode
  */
-static int hrtimer_switch_to_hres(void)
+static int hrtimer_switch_to_hres(struct hrtimer_cpu_base *base)
 {
-	int cpu = smp_processor_id();
-	struct hrtimer_cpu_base *base = &per_cpu(hrtimer_bases, cpu);
 	unsigned long flags;
 
 	if (base->hres_active)
@@ -577,7 +574,7 @@ static int hrtimer_switch_to_hres(void)
 	if (tick_init_highres()) {
 		local_irq_restore(flags);
 		printk(KERN_WARNING "Could not switch to high resolution "
-				    "mode on CPU %d\n", cpu);
+		       "mode on CPU %d\n", raw_smp_processor_id());
 		return 0;
 	}
 	base->hres_active = 1;
@@ -595,9 +592,15 @@ static int hrtimer_switch_to_hres(void)
 
 #else
 
-static inline int hrtimer_hres_active(void) { return 0; }
+static inline int hrtimer_hres_active(struct hrtimer_cpu_base *base)
+{
+	return 0;
+}
 static inline int hrtimer_is_hres_enabled(void) { return 0; }
-static inline int hrtimer_switch_to_hres(void) { return 0; }
+static inline int hrtimer_switch_to_hres(struct hrtimer_cpu_base *base)
+{
+	return 0;
+}
 static inline void hrtimer_force_reprogram(struct hrtimer_cpu_base *base) { }
 static inline int hrtimer_enqueue_reprogram(struct hrtimer *timer,
 					    struct hrtimer_clock_base *base)
@@ -789,7 +792,7 @@ static void __remove_hrtimer(struct hrti
 		if (base->first == &timer->node) {
 			base->first = rb_next(&timer->node);
 			/* Reprogram the clock event device. if enabled */
-			if (reprogram && hrtimer_hres_active())
+			if (reprogram && hrtimer_hres_active(base->cpu_base))
 				hrtimer_force_reprogram(base->cpu_base);
 		}
 		rb_erase(&timer->node, &base->active);
@@ -961,7 +964,7 @@ ktime_t hrtimer_get_next_event(void)
 
 	spin_lock_irqsave(&cpu_base->lock, flags);
 
-	if (!hrtimer_hres_active()) {
+	if (!hrtimer_hres_active(cpu_base)) {
 		for (i = 0; i < HRTIMER_MAX_CLOCK_BASES; i++, base++) {
 			struct hrtimer *timer;
 
@@ -1258,10 +1261,11 @@ static inline void run_hrtimer_queue(str
  */
 void hrtimer_run_queues(void)
 {
-	struct hrtimer_cpu_base *cpu_base = &__get_cpu_var(hrtimer_bases);
+	struct hrtimer_cpu_base *cpu_base;
 	int i;
 
-	if (hrtimer_hres_active())
+	cpu_base = &per_cpu(hrtimer_bases, raw_smp_processor_id());
+	if (hrtimer_hres_active(cpu_base))
 		return;
 
 	/*
@@ -1273,7 +1277,7 @@ void hrtimer_run_queues(void)
 	 * deadlock vs. xtime_lock.
 	 */
 	if (tick_check_oneshot_change(!hrtimer_is_hres_enabled()))
-		if (hrtimer_switch_to_hres())
+		if (hrtimer_switch_to_hres(cpu_base))
 			return;
 
 	hrtimer_get_softirq_time(cpu_base);
Index: linux-rt.q/kernel/sched.c
===================================================================
--- linux-rt.q.orig/kernel/sched.c
+++ linux-rt.q/kernel/sched.c
@@ -3409,7 +3409,7 @@ out:
  */
 static void run_rebalance_domains(struct softirq_action *h)
 {
-	int local_cpu = smp_processor_id();
+	int local_cpu = raw_smp_processor_id();
 	struct rq *local_rq = cpu_rq(local_cpu);
 	enum cpu_idle_type idle = local_rq->idle_at_tick ?
 						CPU_IDLE : CPU_NOT_IDLE;
Index: linux-rt.q/kernel/softirq.c
===================================================================
--- linux-rt.q.orig/kernel/softirq.c
+++ linux-rt.q/kernel/softirq.c
@@ -412,12 +412,12 @@ void do_softirq_from_hardirq(void)
 {
 	unsigned long p_flags;
 
-	if (!local_softirq_pending())
-		return;
 	/*
 	 * 'immediate' softirq execution, from hardirq context:
 	 */
 	local_irq_disable();
+	if (!local_softirq_pending())
+		goto out;
 	__local_bh_disable((unsigned long)__builtin_return_address(0));
 #ifndef CONFIG_PREEMPT_SOFTIRQS
 	trace_softirq_enter();
@@ -437,6 +437,7 @@ void do_softirq_from_hardirq(void)
 	current->flags &= ~PF_SOFTIRQ;
 
 	_local_bh_enable();
+out:
 	local_irq_enable();
 }
 
Index: linux-rt.q/kernel/timer.c
===================================================================
--- linux-rt.q.orig/kernel/timer.c
+++ linux-rt.q/kernel/timer.c
@@ -999,7 +999,7 @@ static inline void update_times(void)
  */
 static void run_timer_softirq(struct softirq_action *h)
 {
-	tvec_base_t *base = __get_cpu_var(tvec_bases);
+	tvec_base_t *base = per_cpu(tvec_bases, raw_smp_processor_id());
 
 	update_times();
 	hrtimer_run_queues();
