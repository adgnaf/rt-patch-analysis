Subject: [patch] nmi-driven profiling for /proc/profile
From: Ingo Molnar <mingo@elte.hu>

nmi-driven profiling for /proc/profile

Signed-off-by: Ingo Molnar <mingo@elte.hu>
---
 arch/x86/kernel/crash.c   |    8 ----
 arch/x86/kernel/irq_64.c  |    2 +
 arch/x86/kernel/nmi_32.c  |   89 ++++++++++++++++++++++++++++++++++++++++++----
 arch/x86/kernel/nmi_64.c  |   65 ++++++++++++++++++++++++++++++++-
 include/asm-x86/apic_32.h |    2 +
 include/asm-x86/apic_64.h |    2 +
 include/linux/profile.h   |    1 
 kernel/profile.c          |    9 +++-
 kernel/time/tick-common.c |    1 
 kernel/time/tick-sched.c  |    2 -
 10 files changed, 157 insertions(+), 24 deletions(-)

Index: linux-2.6.24-rt1/arch/x86/kernel/crash.c
===================================================================
--- linux-2.6.24-rt1.orig/arch/x86/kernel/crash.c	2008-01-25 15:06:45.000000000 -0500
+++ linux-2.6.24-rt1/arch/x86/kernel/crash.c	2008-01-25 15:07:12.000000000 -0500
@@ -78,14 +78,6 @@ static int crash_nmi_callback(struct not
 	return 1;
 }
 
-static void smp_send_nmi_allbutself(void)
-{
-	cpumask_t mask = cpu_online_map;
-	cpu_clear(safe_smp_processor_id(), mask);
-	if (!cpus_empty(mask))
-		send_IPI_mask(mask, NMI_VECTOR);
-}
-
 static struct notifier_block crash_nmi_nb = {
 	.notifier_call = crash_nmi_callback,
 };
Index: linux-2.6.24-rt1/arch/x86/kernel/nmi_32.c
===================================================================
--- linux-2.6.24-rt1.orig/arch/x86/kernel/nmi_32.c	2008-01-25 15:06:53.000000000 -0500
+++ linux-2.6.24-rt1/arch/x86/kernel/nmi_32.c	2008-01-25 15:07:12.000000000 -0500
@@ -25,6 +25,7 @@
 
 #include <asm/smp.h>
 #include <asm/nmi.h>
+#include <asm/mach-default/mach_ipi.h>
 
 #include "mach_traps.h"
 
@@ -42,7 +43,7 @@ static cpumask_t backtrace_mask = CPU_MA
 atomic_t nmi_active = ATOMIC_INIT(0);		/* oprofile uses this */
 
 unsigned int nmi_watchdog = NMI_DEFAULT;
-static unsigned int nmi_hz = HZ;
+static unsigned int nmi_hz = 1000;
 
 static DEFINE_PER_CPU(short, wd_enabled);
 
@@ -93,7 +94,7 @@ static int __init check_nmi_watchdog(voi
 	for_each_possible_cpu(cpu)
 		prev_nmi_count[cpu] = per_cpu(irq_stat, cpu).__nmi_count;
 	local_irq_enable();
-	mdelay((20*1000)/nmi_hz); // wait 20 ticks
+	mdelay((100*1000)/nmi_hz); /* wait 100 ticks */
 
 	for_each_possible_cpu(cpu) {
 #ifdef CONFIG_SMP
@@ -318,6 +319,46 @@ EXPORT_SYMBOL(touch_nmi_watchdog);
 
 extern void die_nmi(struct pt_regs *, const char *msg);
 
+int nmi_show_regs[NR_CPUS];
+
+void nmi_show_all_regs(void)
+{
+	int i;
+
+	if (system_state == SYSTEM_BOOTING)
+		return;
+
+	printk(KERN_WARNING "nmi_show_all_regs(): start on CPU#%d.\n",
+		raw_smp_processor_id());
+	dump_stack();
+
+	for_each_online_cpu(i)
+		nmi_show_regs[i] = 1;
+
+	smp_send_nmi_allbutself();
+
+	for_each_online_cpu(i) {
+		while (nmi_show_regs[i] == 1)
+			barrier();
+	}
+}
+
+static DEFINE_SPINLOCK(nmi_print_lock);
+
+void irq_show_regs_callback(int cpu, struct pt_regs *regs)
+{
+	if (!nmi_show_regs[cpu])
+		return;
+
+	nmi_show_regs[cpu] = 0;
+	spin_lock(&nmi_print_lock);
+	printk(KERN_WARNING "NMI show regs on CPU#%d:\n", cpu);
+	printk(KERN_WARNING "apic_timer_irqs: %d\n",
+		per_cpu(irq_stat, cpu).apic_timer_irqs);
+	show_regs(regs);
+	spin_unlock(&nmi_print_lock);
+}
+
 notrace __kprobes int nmi_watchdog_tick(struct pt_regs *regs, unsigned reason)
 {
 
@@ -331,6 +372,8 @@ notrace __kprobes int nmi_watchdog_tick(
 	int cpu = smp_processor_id();
 	int rc=0;
 
+	__profile_tick(CPU_PROFILING, regs);
+
 	/* check for other users first */
 	if (notify_die(DIE_NMI, "nmi", regs, reason, 2, SIGINT)
 			== NOTIFY_STOP) {
@@ -355,6 +398,9 @@ notrace __kprobes int nmi_watchdog_tick(
 	sum = per_cpu(irq_stat, cpu).apic_timer_irqs +
 		per_cpu(irq_stat, cpu).irq0_irqs;
 
+	irq_show_regs_callback(cpu, regs);
+
+	/* if the apic timer isn't firing, this cpu isn't doing much */
 	/* if the none of the timers isn't firing, this cpu isn't doing much */
 	if (!touched && last_irq_sums[cpu] == sum) {
 		/*
@@ -362,11 +408,30 @@ notrace __kprobes int nmi_watchdog_tick(
 		 * wait a few IRQs (5 seconds) before doing the oops ...
 		 */
 		alert_counter[cpu]++;
-		if (alert_counter[cpu] == 5*nmi_hz)
-			/*
-			 * die_nmi will return ONLY if NOTIFY_STOP happens..
-			 */
-			die_nmi(regs, "BUG: NMI Watchdog detected LOCKUP");
+		if (alert_counter[cpu] && !(alert_counter[cpu] % (5*nmi_hz))) {
+			int i;
+
+			spin_lock(&nmi_print_lock);
+			printk(KERN_WARNING "NMI watchdog detected lockup on "
+				"CPU#%d (%d/%d)\n", cpu, alert_counter[cpu],
+						    5*nmi_hz);
+			show_regs(regs);
+			spin_unlock(&nmi_print_lock);
+
+			for_each_online_cpu(i) {
+				if (i == cpu)
+					continue;
+				nmi_show_regs[i] = 1;
+				while (nmi_show_regs[i] == 1)
+					cpu_relax();
+			}
+			printk(KERN_WARNING "NMI watchdog running again ...\n");
+			for_each_online_cpu(i)
+				alert_counter[i] = 0;
+
+
+		}
+
 	} else {
 		last_irq_sums[cpu] = sum;
 		alert_counter[cpu] = 0;
@@ -464,5 +529,15 @@ void __trigger_all_cpu_backtrace(void)
 	}
 }
 
+void smp_send_nmi_allbutself(void)
+{
+#ifdef CONFIG_SMP
+	cpumask_t mask = cpu_online_map;
+	cpu_clear(safe_smp_processor_id(), mask);
+	if (!cpus_empty(mask))
+		send_IPI_mask(mask, NMI_VECTOR);
+#endif
+}
+
 EXPORT_SYMBOL(nmi_active);
 EXPORT_SYMBOL(nmi_watchdog);
Index: linux-2.6.24-rt1/arch/x86/kernel/irq_64.c
===================================================================
--- linux-2.6.24-rt1.orig/arch/x86/kernel/irq_64.c	2008-01-25 15:06:45.000000000 -0500
+++ linux-2.6.24-rt1/arch/x86/kernel/irq_64.c	2008-01-25 15:07:12.000000000 -0500
@@ -145,6 +145,8 @@ asmlinkage unsigned int do_IRQ(struct pt
 	unsigned vector = ~regs->orig_rax;
 	unsigned irq;
 
+	irq_show_regs_callback(smp_processor_id(), regs);
+
 	exit_idle();
 	irq_enter();
 	irq = __get_cpu_var(vector_irq)[vector];
Index: linux-2.6.24-rt1/arch/x86/kernel/nmi_64.c
===================================================================
--- linux-2.6.24-rt1.orig/arch/x86/kernel/nmi_64.c	2008-01-25 15:06:53.000000000 -0500
+++ linux-2.6.24-rt1/arch/x86/kernel/nmi_64.c	2008-01-25 15:07:12.000000000 -0500
@@ -20,11 +20,13 @@
 #include <linux/kprobes.h>
 #include <linux/cpumask.h>
 #include <linux/kdebug.h>
+#include <linux/kernel_stat.h>
 
 #include <asm/smp.h>
 #include <asm/nmi.h>
 #include <asm/proto.h>
 #include <asm/mce.h>
+#include <asm/mach_apic.h>
 
 int unknown_nmi_panic;
 int nmi_watchdog_enabled;
@@ -42,7 +44,7 @@ atomic_t nmi_active = ATOMIC_INIT(0);		/
 int panic_on_timeout;
 
 unsigned int nmi_watchdog = NMI_DEFAULT;
-static unsigned int nmi_hz = HZ;
+static unsigned int nmi_hz = 1000;
 
 static DEFINE_PER_CPU(short, wd_enabled);
 
@@ -301,7 +303,7 @@ void touch_nmi_watchdog(void)
 		unsigned cpu;
 
 		/*
- 		 * Tell other CPUs to reset their alert counters. We cannot
+		 * Tell other CPUs to reset their alert counters. We cannot
 		 * do it ourselves because the alert count increase is not
 		 * atomic.
 		 */
@@ -312,6 +314,42 @@ void touch_nmi_watchdog(void)
 	}
 
  	touch_softlockup_watchdog();
+	touch_softlockup_watchdog();
+}
+
+int nmi_show_regs[NR_CPUS];
+
+void nmi_show_all_regs(void)
+{
+	int i;
+
+	if (system_state == SYSTEM_BOOTING)
+		return;
+
+	smp_send_nmi_allbutself();
+
+	for_each_online_cpu(i)
+		nmi_show_regs[i] = 1;
+
+	for_each_online_cpu(i) {
+		while (nmi_show_regs[i] == 1)
+			barrier();
+	}
+}
+
+static DEFINE_SPINLOCK(nmi_print_lock);
+
+void irq_show_regs_callback(int cpu, struct pt_regs *regs)
+{
+	if (!nmi_show_regs[cpu])
+		return;
+
+	nmi_show_regs[cpu] = 0;
+	spin_lock(&nmi_print_lock);
+	printk(KERN_WARNING "NMI show regs on CPU#%d:\n", cpu);
+	printk(KERN_WARNING "apic_timer_irqs: %d\n", read_pda(apic_timer_irqs));
+	show_regs(regs);
+	spin_unlock(&nmi_print_lock);
 }
 
 notrace __kprobes int nmi_watchdog_tick(struct pt_regs *regs, unsigned reason)
@@ -321,6 +359,9 @@ notrace __kprobes int nmi_watchdog_tick(
 	int cpu = smp_processor_id();
 	int rc = 0;
 
+	irq_show_regs_callback(cpu, regs);
+	__profile_tick(CPU_PROFILING, regs);
+
 	/* check for other users first */
 	if (notify_die(DIE_NMI, "nmi", regs, reason, 2, SIGINT)
 			== NOTIFY_STOP) {
@@ -357,9 +398,20 @@ notrace __kprobes int nmi_watchdog_tick(
 		 * wait a few IRQs (5 seconds) before doing the oops ...
 		 */
 		local_inc(&__get_cpu_var(alert_counter));
-		if (local_read(&__get_cpu_var(alert_counter)) == 5*nmi_hz)
+		if (local_read(&__get_cpu_var(alert_counter)) == 5*nmi_hz) {
+			int i;
+
+			for_each_online_cpu(i) {
+				if (i == cpu)
+					continue;
+				nmi_show_regs[i] = 1;
+				while (nmi_show_regs[i] == 1)
+					cpu_relax();
+			}
+
 			die_nmi("NMI Watchdog detected LOCKUP on CPU %d\n", regs,
 				panic_on_timeout);
+		}
 	} else {
 		__get_cpu_var(last_irq_sum) = sum;
 		local_set(&__get_cpu_var(alert_counter), 0);
@@ -477,6 +529,13 @@ void __trigger_all_cpu_backtrace(void)
 	}
 }
 
+void smp_send_nmi_allbutself(void)
+{
+#ifdef CONFIG_SMP
+	send_IPI_allbutself(NMI_VECTOR);
+#endif
+}
+
 EXPORT_SYMBOL(nmi_active);
 EXPORT_SYMBOL(nmi_watchdog);
 EXPORT_SYMBOL(touch_nmi_watchdog);
Index: linux-2.6.24-rt1/include/asm-x86/apic_32.h
===================================================================
--- linux-2.6.24-rt1.orig/include/asm-x86/apic_32.h	2008-01-25 15:06:46.000000000 -0500
+++ linux-2.6.24-rt1/include/asm-x86/apic_32.h	2008-01-25 15:07:12.000000000 -0500
@@ -118,6 +118,8 @@ extern int local_apic_timer_c2_ok;
 
 extern int local_apic_timer_disabled;
 
+extern void smp_send_nmi_allbutself(void);
+
 #else /* !CONFIG_X86_LOCAL_APIC */
 static inline void lapic_shutdown(void) { }
 #define local_apic_timer_c2_ok		1
Index: linux-2.6.24-rt1/include/asm-x86/apic_64.h
===================================================================
--- linux-2.6.24-rt1.orig/include/asm-x86/apic_64.h	2008-01-25 15:06:46.000000000 -0500
+++ linux-2.6.24-rt1/include/asm-x86/apic_64.h	2008-01-25 15:07:12.000000000 -0500
@@ -87,6 +87,8 @@ extern void setup_APIC_extended_lvt(unsi
 
 extern int apic_is_clustered_box(void);
 
+extern void smp_send_nmi_allbutself(void);
+
 #define K8_APIC_EXT_LVT_BASE    0x500
 #define K8_APIC_EXT_INT_MSG_FIX 0x0
 #define K8_APIC_EXT_INT_MSG_SMI 0x2
Index: linux-2.6.24-rt1/include/linux/profile.h
===================================================================
--- linux-2.6.24-rt1.orig/include/linux/profile.h	2008-01-25 15:06:46.000000000 -0500
+++ linux-2.6.24-rt1/include/linux/profile.h	2008-01-25 15:07:12.000000000 -0500
@@ -23,6 +23,7 @@ struct notifier_block;
 
 /* init basic kernel profiler */
 void __init profile_init(void);
+void __profile_tick(int type, struct pt_regs *regs);
 void profile_tick(int);
 
 /*
Index: linux-2.6.24-rt1/kernel/profile.c
===================================================================
--- linux-2.6.24-rt1.orig/kernel/profile.c	2008-01-25 15:06:46.000000000 -0500
+++ linux-2.6.24-rt1/kernel/profile.c	2008-01-25 15:07:12.000000000 -0500
@@ -412,16 +412,19 @@ void profile_hits(int type, void *__pc, 
 
 EXPORT_SYMBOL_GPL(profile_hits);
 
-void profile_tick(int type)
+void __profile_tick(int type, struct pt_regs *regs)
 {
-	struct pt_regs *regs = get_irq_regs();
-
 	if (type == CPU_PROFILING && timer_hook)
 		timer_hook(regs);
 	if (!user_mode(regs) && cpu_isset(smp_processor_id(), prof_cpu_mask))
 		profile_hit(type, (void *)profile_pc(regs));
 }
 
+void profile_tick(int type)
+{
+	return __profile_tick(type, get_irq_regs());
+}
+
 #ifdef CONFIG_PROC_FS
 #include <linux/proc_fs.h>
 #include <asm/uaccess.h>
Index: linux-2.6.24-rt1/kernel/time/tick-common.c
===================================================================
--- linux-2.6.24-rt1.orig/kernel/time/tick-common.c	2008-01-25 15:06:46.000000000 -0500
+++ linux-2.6.24-rt1/kernel/time/tick-common.c	2008-01-25 15:07:12.000000000 -0500
@@ -68,7 +68,6 @@ static void tick_periodic(int cpu)
 	}
 
 	update_process_times(user_mode(get_irq_regs()));
-	profile_tick(CPU_PROFILING);
 }
 
 /*
Index: linux-2.6.24-rt1/kernel/time/tick-sched.c
===================================================================
--- linux-2.6.24-rt1.orig/kernel/time/tick-sched.c	2008-01-25 15:06:46.000000000 -0500
+++ linux-2.6.24-rt1/kernel/time/tick-sched.c	2008-01-25 15:07:12.000000000 -0500
@@ -440,7 +440,6 @@ static void tick_nohz_handler(struct clo
 	}
 
 	update_process_times(user_mode(regs));
-	profile_tick(CPU_PROFILING);
 
 	/* Do not restart, when we are in the idle loop */
 	if (ts->tick_stopped)
@@ -554,7 +553,6 @@ static enum hrtimer_restart tick_sched_t
 		 */
 		spin_unlock(&base->lock);
 		update_process_times(user_mode(regs));
-		profile_tick(CPU_PROFILING);
 		spin_lock(&base->lock);
 	}
 
