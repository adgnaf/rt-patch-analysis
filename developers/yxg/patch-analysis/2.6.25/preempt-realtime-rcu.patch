---
 include/linux/rcuclassic.h |    2 +-
 kernel/rcuclassic.c        |    4 ++--
 kernel/rcupreempt-boost.c  |    4 ++--
 kernel/rcupreempt.c        |    6 +++---
 4 files changed, 8 insertions(+), 8 deletions(-)

Index: linux-2.6.25.4-rt1/kernel/rcupreempt.c
===================================================================
--- linux-2.6.25.4-rt1.orig/kernel/rcupreempt.c	2008-05-17 08:26:51.000000000 -0400
+++ linux-2.6.25.4-rt1/kernel/rcupreempt.c	2008-05-17 08:27:38.000000000 -0400
@@ -79,7 +79,7 @@
  */
 #define GP_STAGES    2
 struct rcu_data {
-	spinlock_t	lock;		/* Protect rcu_data fields. */
+	raw_spinlock_t	lock;		/* Protect rcu_data fields. */
 	long		completed;	/* Number of last completed batch. */
 	int		waitlistcount;
 	struct tasklet_struct rcu_tasklet;
@@ -132,7 +132,7 @@ enum rcu_try_flip_states {
 };
 
 struct rcu_ctrlblk {
-	spinlock_t	fliplock;	/* Protect state-machine transitions. */
+	raw_spinlock_t	fliplock;	/* Protect state-machine transitions. */
 	long		completed;	/* Number of last completed batch. */
 	enum rcu_try_flip_states rcu_try_flip_state; /* The current state of
 							the rcu state machine */
@@ -140,7 +140,7 @@ struct rcu_ctrlblk {
 
 static DEFINE_PER_CPU(struct rcu_data, rcu_data);
 static struct rcu_ctrlblk rcu_ctrlblk = {
-	.fliplock = __SPIN_LOCK_UNLOCKED(rcu_ctrlblk.fliplock),
+	.fliplock = RAW_SPIN_LOCK_UNLOCKED(rcu_ctrlblk.fliplock),
 	.completed = 0,
 	.rcu_try_flip_state = rcu_try_flip_idle_state,
 };
Index: linux-2.6.25.4-rt1/kernel/rcuclassic.c
===================================================================
--- linux-2.6.25.4-rt1.orig/kernel/rcuclassic.c	2008-05-17 08:26:50.000000000 -0400
+++ linux-2.6.25.4-rt1/kernel/rcuclassic.c	2008-05-17 08:27:38.000000000 -0400
@@ -60,13 +60,13 @@ EXPORT_SYMBOL_GPL(rcu_lock_map);
 static struct rcu_ctrlblk rcu_ctrlblk = {
 	.cur = -300,
 	.completed = -300,
-	.lock = __SPIN_LOCK_UNLOCKED(&rcu_ctrlblk.lock),
+	.lock = RAW_SPIN_LOCK_UNLOCKED(&rcu_ctrlblk.lock),
 	.cpumask = CPU_MASK_NONE,
 };
 static struct rcu_ctrlblk rcu_bh_ctrlblk = {
 	.cur = -300,
 	.completed = -300,
-	.lock = __SPIN_LOCK_UNLOCKED(&rcu_bh_ctrlblk.lock),
+	.lock = RAW_SPIN_LOCK_UNLOCKED(&rcu_bh_ctrlblk.lock),
 	.cpumask = CPU_MASK_NONE,
 };
 
Index: linux-2.6.25.4-rt1/include/linux/rcuclassic.h
===================================================================
--- linux-2.6.25.4-rt1.orig/include/linux/rcuclassic.h	2008-05-17 08:26:51.000000000 -0400
+++ linux-2.6.25.4-rt1/include/linux/rcuclassic.h	2008-05-17 08:27:38.000000000 -0400
@@ -51,7 +51,7 @@ struct rcu_ctrlblk {
 
 	int	signaled;
 
-	spinlock_t	lock	____cacheline_internodealigned_in_smp;
+	raw_spinlock_t	lock	____cacheline_internodealigned_in_smp;
 	cpumask_t	cpumask; /* CPUs that need to switch in order    */
 				 /* for current batch to proceed.        */
 } ____cacheline_internodealigned_in_smp;
Index: linux-2.6.25.4-rt1/kernel/rcupreempt-boost.c
===================================================================
--- linux-2.6.25.4-rt1.orig/kernel/rcupreempt-boost.c	2008-05-17 08:26:51.000000000 -0400
+++ linux-2.6.25.4-rt1/kernel/rcupreempt-boost.c	2008-05-17 08:27:38.000000000 -0400
@@ -30,13 +30,13 @@
 #include <linux/syscalls.h>
 #include <linux/kthread.h>
 
-DEFINE_SPINLOCK(rcu_boost_wake_lock);
+DEFINE_RAW_SPINLOCK(rcu_boost_wake_lock);
 static int rcu_boost_prio = MAX_PRIO;	/* Prio to set preempted RCU readers */
 static long rcu_boost_counter;		/* used to keep track of who boosted */
 static int rcu_preempt_thread_secs = 3;	/* Seconds between waking rcupreemptd thread */
 
 struct rcu_boost_dat {
-	spinlock_t rbs_lock;		/* Sync changes to this struct */
+	raw_spinlock_t rbs_lock;	/* Sync changes to this struct */
 	int rbs_prio;			/* CPU copy of rcu_boost_prio  */
 	struct list_head rbs_toboost;	/* Preempted RCU readers       */
 	struct list_head rbs_boosted;	/* RCU readers that have been boosted */
