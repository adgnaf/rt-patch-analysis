From prasad@linux.vnet.ibm.com Fri Jan 11 14:55:27 2008
Date: Tue, 8 Jan 2008 01:25:09 +0530
From: K. Prasad <prasad@linux.vnet.ibm.com>
To: linux-kernel@vger.kernel.org, mingo@elte.hu
Cc: Gautham R Shenoy <ego@in.ibm.com>, K. Prasad <prasad@linux.vnet.ibm.com>,
     mathieu.desnoyers@polymtl.ca, linux-rt-users@vger.kernel.org,
     dipankar@in.ibm.com, paulmck@linux.vnet.ibm.com
Subject: [PATCH 1/2] Markers Implementation for RCU Preempt Tracing - Ver II

This patch converts Preempt RCU Tracing code infrastructure to implement
markers.
 
- The rcupreempt_trace structure has been moved to the tracing
  infrastructure and de-linked from the rcupreempt.c code. A per-cpu
  instance of rcupreempt_trace structure will be maintained in
  rcupreempt_trace.c
 
- The above change also renders a few macro definitions unused (such as
  RCU_TRACE_CPU, RCU_TRACE_ME and RCU_TRACE_RDP) which have been
  removed.
 
- Some of the helper functions in rcupreempt.c which were exported only
  when CONFIG_RCU_TRACE was set are now exported unconditionally. These
  functions operate on per-cpu variables that are used both by the RCU
  and RCU Tracing code. The changes help in making RCU Tracing code
  operate as a kernel module also.
 
- The references to rcupreempt-boost tracing in the module
  initialisation and cleanup have been removed here to enable kernel
  build, but will be brought in after enclosing them inside a #ifdef
  CONFIG_PREEMPT_RCU_BOOST.
 
Signed-off-by: K.Prasad <prasad@linux.vnet.ibm.com>
---
 include/linux/rcupreempt.h       |   10 ----
 include/linux/rcupreempt_trace.h |   50 ++++++++++++------------
 kernel/Kconfig.preempt           |    7 +--
 kernel/rcupreempt.c              |   77 ++++++++++----------------------------
 kernel/rcupreempt_trace.c        |   79 +++++++++++++++++++++++++++++++++++++--
 5 files changed, 125 insertions(+), 98 deletions(-)
 
Index: linux-2.6.25-rt1/include/linux/rcupreempt.h
===================================================================
--- linux-2.6.25-rt1.orig/include/linux/rcupreempt.h	2008-04-30 14:53:37.000000000 -0400
+++ linux-2.6.25-rt1/include/linux/rcupreempt.h	2008-04-30 14:53:39.000000000 -0400
@@ -102,16 +102,6 @@ static inline long rcu_batches_completed
 	return rcu_batches_completed();
 }
 
-#ifdef CONFIG_RCU_TRACE
-struct rcupreempt_trace;
-extern long *rcupreempt_flipctr(int cpu);
-extern long rcupreempt_data_completed(void);
-extern int rcupreempt_flip_flag(int cpu);
-extern int rcupreempt_mb_flag(int cpu);
-extern char *rcupreempt_try_flip_state_name(void);
-extern struct rcupreempt_trace *rcupreempt_trace_cpu(int cpu);
-#endif
-
 struct softirq_action;
 
 #ifdef CONFIG_NO_HZ
Index: linux-2.6.25-rt1/include/linux/rcupreempt_trace.h
===================================================================
--- linux-2.6.25-rt1.orig/include/linux/rcupreempt_trace.h	2008-04-30 13:36:50.000000000 -0400
+++ linux-2.6.25-rt1/include/linux/rcupreempt_trace.h	2008-04-30 14:53:39.000000000 -0400
@@ -68,32 +68,32 @@ struct rcupreempt_trace {
 	long		rcu_try_flip_m2;
 };
 
-#ifdef CONFIG_RCU_TRACE
-#define RCU_TRACE(fn, arg) 	fn(arg);
-#else
-#define RCU_TRACE(fn, arg)
-#endif
+struct rcupreempt_probe_data {
+	const char *name;
+	const char *format;
+	marker_probe_func *probe_func;
+};
+
+#define DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_worker) \
+void rcupreempt_trace_worker##_callback(const struct marker *mdata, \
+				void *private_data, const char *format, ...) \
+{ \
+	struct rcupreempt_trace *trace; \
+	trace = (&per_cpu(trace_data, smp_processor_id())); \
+	rcupreempt_trace_worker(trace); \
+}
+
+#define INIT_RCUPREEMPT_PROBE(rcupreempt_trace_worker) \
+{ \
+	.name = __stringify(rcupreempt_trace_worker), \
+	.probe_func = rcupreempt_trace_worker##_callback \
+}
 
-extern void rcupreempt_trace_move2done(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_move2wait(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_1(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_e1(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_i1(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_ie1(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_g1(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_a1(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_ae1(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_a2(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_z1(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_ze1(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_z2(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_m1(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_me1(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_try_flip_m2(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_check_callbacks(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_done_remove(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_invoke(struct rcupreempt_trace *trace);
-extern void rcupreempt_trace_next_add(struct rcupreempt_trace *trace);
+extern int *rcupreempt_flipctr(int cpu);
+extern long rcupreempt_data_completed(void);
+extern int rcupreempt_flip_flag(int cpu);
+extern int rcupreempt_mb_flag(int cpu);
+extern char *rcupreempt_try_flip_state_name(void);
 
 #endif /* __KERNEL__ */
 #endif /* __LINUX_RCUPREEMPT_TRACE_H */
Index: linux-2.6.25-rt1/kernel/rcupreempt.c
===================================================================
--- linux-2.6.25-rt1.orig/kernel/rcupreempt.c	2008-04-30 14:47:02.000000000 -0400
+++ linux-2.6.25-rt1/kernel/rcupreempt.c	2008-04-30 14:58:25.000000000 -0400
@@ -56,7 +56,6 @@
 #include <linux/delay.h>
 #include <linux/byteorder/swabb.h>
 #include <linux/cpumask.h>
-#include <linux/rcupreempt_trace.h>
 
 /*
  * Macro that prevents the compiler from reordering accesses, but does
@@ -90,9 +89,6 @@ struct rcu_data {
 	struct rcu_head *donelist;
 	struct rcu_head **donetail;
 	long rcu_flipctr[2];
-#ifdef CONFIG_RCU_TRACE
-	struct rcupreempt_trace trace;
-#endif /* #ifdef CONFIG_RCU_TRACE */
 };
 
 /*
@@ -146,10 +142,8 @@ static struct rcu_ctrlblk rcu_ctrlblk = 
 };
 
 
-#ifdef CONFIG_RCU_TRACE
 static char *rcu_try_flip_state_names[] =
 	{ "idle", "waitack", "waitzero", "waitmb" };
-#endif /* #ifdef CONFIG_RCU_TRACE */
 
 static cpumask_t rcu_cpu_online_map __read_mostly = CPU_MASK_NONE;
 
@@ -190,24 +184,6 @@ static DEFINE_PER_CPU_SHARED_ALIGNED(enu
 #define RCU_DATA_CPU(cpu)	(&per_cpu(rcu_data, cpu))
 
 /*
- * Helper macro for tracing when the appropriate rcu_data is not
- * cached in a local variable, but where the CPU number is so cached.
- */
-#define RCU_TRACE_CPU(f, cpu) RCU_TRACE(f, &(RCU_DATA_CPU(cpu)->trace));
-
-/*
- * Helper macro for tracing when the appropriate rcu_data is not
- * cached in a local variable.
- */
-#define RCU_TRACE_ME(f) RCU_TRACE(f, &(RCU_DATA_ME()->trace));
-
-/*
- * Helper macro for tracing when the appropriate rcu_data is pointed
- * to by a local variable.
- */
-#define RCU_TRACE_RDP(f, rdp) RCU_TRACE(f, &((rdp)->trace));
-
-/*
  * Return the number of RCU batches processed thus far.  Useful
  * for debug and statistics.
  */
@@ -372,7 +348,7 @@ static void __rcu_advance_callbacks(stru
 		if (rdp->waitlist[GP_STAGES - 1] != NULL) {
 			*rdp->donetail = rdp->waitlist[GP_STAGES - 1];
 			rdp->donetail = rdp->waittail[GP_STAGES - 1];
-			RCU_TRACE_RDP(rcupreempt_trace_move2done, rdp);
+			trace_mark(rcupreempt_trace_move2done, "NULL");
 		}
 		for (i = GP_STAGES - 2; i >= 0; i--) {
 			if (rdp->waitlist[i] != NULL) {
@@ -391,7 +367,7 @@ static void __rcu_advance_callbacks(stru
 			wlc++;
 			rdp->nextlist = NULL;
 			rdp->nexttail = &rdp->nextlist;
-			RCU_TRACE_RDP(rcupreempt_trace_move2wait, rdp);
+			trace_mark(rcupreempt_trace_move2wait, "NULL");
 		} else {
 			rdp->waitlist[0] = NULL;
 			rdp->waittail[0] = &rdp->waitlist[0];
@@ -636,9 +612,9 @@ rcu_try_flip_idle(void)
 {
 	int cpu;
 
-	RCU_TRACE_ME(rcupreempt_trace_try_flip_i1);
+	trace_mark(rcupreempt_trace_try_flip_i1, "NULL");
 	if (!rcu_pending(smp_processor_id())) {
-		RCU_TRACE_ME(rcupreempt_trace_try_flip_ie1);
+		trace_mark(rcupreempt_trace_try_flip_ie1, "NULL");
 		return 0;
 	}
 
@@ -646,7 +622,7 @@ rcu_try_flip_idle(void)
 	 * Do the flip.
 	 */
 
-	RCU_TRACE_ME(rcupreempt_trace_try_flip_g1);
+	trace_mark(rcupreempt_trace_try_flip_g1, "NULL");
 	rcu_ctrlblk.completed++;  /* stands in for rcu_try_flip_g2 */
 
 	/*
@@ -676,11 +652,11 @@ rcu_try_flip_waitack(void)
 {
 	int cpu;
 
-	RCU_TRACE_ME(rcupreempt_trace_try_flip_a1);
+	trace_mark(rcupreempt_trace_try_flip_a1, "NULL");
 	for_each_cpu_mask(cpu, rcu_cpu_online_map)
 		if (rcu_try_flip_waitack_needed(cpu) &&
 		    per_cpu(rcu_flip_flag, cpu) != rcu_flip_seen) {
-			RCU_TRACE_ME(rcupreempt_trace_try_flip_ae1);
+			trace_mark(rcupreempt_trace_try_flip_ae1, "NULL");
 			return 0;
 		}
 
@@ -690,7 +666,7 @@ rcu_try_flip_waitack(void)
 	 */
 
 	smp_mb();	/* see above block comment. */
-	RCU_TRACE_ME(rcupreempt_trace_try_flip_a2);
+	trace_mark(rcupreempt_trace_try_flip_a2, "NULL");
 	return 1;
 }
 
@@ -708,11 +684,11 @@ rcu_try_flip_waitzero(void)
 
 	/* Check to see if the sum of the "last" counters is zero. */
 
-	RCU_TRACE_ME(rcupreempt_trace_try_flip_z1);
+	trace_mark(rcupreempt_trace_try_flip_z1, "NULL");
 	for_each_cpu_mask(cpu, rcu_cpu_online_map)
 		sum += RCU_DATA_CPU(cpu)->rcu_flipctr[lastidx];
 	if (sum != 0) {
-		RCU_TRACE_ME(rcupreempt_trace_try_flip_ze1);
+		trace_mark(rcupreempt_trace_try_flip_ze1, "NULL");
 		return 0;
 	}
 
@@ -729,7 +705,7 @@ rcu_try_flip_waitzero(void)
 		dyntick_save_progress_counter(cpu);
 	}
 
-	RCU_TRACE_ME(rcupreempt_trace_try_flip_z2);
+	trace_mark(rcupreempt_trace_try_flip_z2, "NULL");
 	return 1;
 }
 
@@ -743,16 +719,16 @@ rcu_try_flip_waitmb(void)
 {
 	int cpu;
 
-	RCU_TRACE_ME(rcupreempt_trace_try_flip_m1);
+	trace_mark(rcupreempt_trace_try_flip_m1, "NULL");
 	for_each_cpu_mask(cpu, rcu_cpu_online_map)
 		if (rcu_try_flip_waitmb_needed(cpu) &&
 		    per_cpu(rcu_mb_flag, cpu) != rcu_mb_done) {
-			RCU_TRACE_ME(rcupreempt_trace_try_flip_me1);
+			trace_mark(rcupreempt_trace_try_flip_me1, "NULL");
 			return 0;
 		}
 
 	smp_mb(); /* Ensure that the above checks precede any following flip. */
-	RCU_TRACE_ME(rcupreempt_trace_try_flip_m2);
+	trace_mark(rcupreempt_trace_try_flip_m2, "NULL");
 	return 1;
 }
 
@@ -769,9 +745,9 @@ static void rcu_try_flip(void)
 {
 	unsigned long flags;
 
-	RCU_TRACE_ME(rcupreempt_trace_try_flip_1);
+	trace_mark(rcupreempt_trace_try_flip_1, "NULL");
 	if (unlikely(!spin_trylock_irqsave(&rcu_ctrlblk.fliplock, flags))) {
-		RCU_TRACE_ME(rcupreempt_trace_try_flip_e1);
+		trace_mark(rcupreempt_trace_try_flip_e1, "NULL");
 		return;
 	}
 
@@ -827,7 +803,7 @@ void rcu_check_callbacks(int cpu, int us
 	if (rcu_ctrlblk.completed == rdp->completed)
 		rcu_try_flip();
 	spin_lock_irqsave(&rdp->lock, flags);
-	RCU_TRACE_RDP(rcupreempt_trace_check_callbacks, rdp);
+	trace_mark(rcupreempt_trace_check_callbacks, "NULL");
 	__rcu_advance_callbacks(rdp);
 	if (rdp->donelist == NULL) {
 		spin_unlock_irqrestore(&rdp->lock, flags);
@@ -852,7 +828,7 @@ void rcu_advance_callbacks(int cpu, int 
 			return;
 	}
 	spin_lock_irqsave(&rdp->lock, flags);
-	RCU_TRACE_RDP(rcupreempt_trace_check_callbacks, rdp);
+	trace_mark(rcupreempt_trace_check_callbacks, "NULL");
 	__rcu_advance_callbacks(rdp);
 	spin_unlock_irqrestore(&rdp->lock, flags);
 }
@@ -966,13 +942,13 @@ void rcu_process_callbacks(struct softir
 	}
 	rdp->donelist = NULL;
 	rdp->donetail = &rdp->donelist;
-	RCU_TRACE_RDP(rcupreempt_trace_done_remove, rdp);
+	trace_mark(rcupreempt_trace_done_remove, "NULL");
 	spin_unlock_irqrestore(&rdp->lock, flags);
 	while (list) {
 		next = list->next;
 		list->func(list);
 		list = next;
-		RCU_TRACE_ME(rcupreempt_trace_invoke);
+		trace_mark(rcupreempt_trace_invoke, "NULL");
 	}
 }
 
@@ -989,7 +965,7 @@ void call_rcu(struct rcu_head *head, voi
 	__rcu_advance_callbacks(rdp);
 	*rdp->nexttail = head;
 	rdp->nexttail = &head->next;
-	RCU_TRACE_RDP(rcupreempt_trace_next_add, rdp);
+	trace_mark(rcupreempt_trace_next_add, "NULL");
 	spin_unlock(&rdp->lock);
 	local_irq_restore(flags);
 }
@@ -1140,7 +1116,6 @@ void synchronize_kernel(void)
 	synchronize_rcu();
 }
 
-#ifdef CONFIG_RCU_TRACE
 long *rcupreempt_flipctr(int cpu)
 {
 	return &RCU_DATA_CPU(cpu)->rcu_flipctr[0];
@@ -1164,13 +1139,3 @@ char *rcupreempt_try_flip_state_name(voi
 	return rcu_try_flip_state_names[rcu_ctrlblk.rcu_try_flip_state];
 }
 EXPORT_SYMBOL_GPL(rcupreempt_try_flip_state_name);
-
-struct rcupreempt_trace *rcupreempt_trace_cpu(int cpu)
-{
-	struct rcu_data *rdp = RCU_DATA_CPU(cpu);
-
-	return &rdp->trace;
-}
-EXPORT_SYMBOL_GPL(rcupreempt_trace_cpu);
-
-#endif /* #ifdef RCU_TRACE */
Index: linux-2.6.25-rt1/kernel/rcupreempt_trace.c
===================================================================
--- linux-2.6.25-rt1.orig/kernel/rcupreempt_trace.c	2008-04-30 13:56:37.000000000 -0400
+++ linux-2.6.25-rt1/kernel/rcupreempt_trace.c	2008-04-30 14:53:39.000000000 -0400
@@ -43,11 +43,19 @@
 #include <linux/mutex.h>
 #include <linux/rcupreempt_trace.h>
 #include <linux/debugfs.h>
+#include <linux/percpu.h>
 
 static struct mutex rcupreempt_trace_mutex;
 static char *rcupreempt_trace_buf;
 #define RCUPREEMPT_TRACE_BUF_SIZE 4096
 
+static DEFINE_PER_CPU(struct rcupreempt_trace, trace_data);
+
+struct rcupreempt_trace *rcupreempt_trace_cpu(int cpu)
+{
+	return &per_cpu(trace_data, cpu);
+}
+
 void rcupreempt_trace_move2done(struct rcupreempt_trace *trace)
 {
 	trace->done_length += trace->wait_length;
@@ -135,6 +143,51 @@ void rcupreempt_trace_next_add(struct rc
 	trace->next_length++;
 }
 
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_move2done);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_move2wait);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_1);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_e1);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_i1);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_ie1);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_g1);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_a1);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_ae1);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_a2);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_z1);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_ze1);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_z2);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_m1);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_me1);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_try_flip_m2);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_check_callbacks);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_done_remove);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_invoke);
+DEFINE_RCUPREEMPT_MARKER_HANDLER(rcupreempt_trace_next_add);
+
+static struct rcupreempt_probe_data rcupreempt_probe_array[] =
+{
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_move2done),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_move2wait),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_1),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_e1),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_i1),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_ie1),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_g1),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_a1),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_ae1),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_a2),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_z1),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_ze1),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_z2),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_m1),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_me1),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_try_flip_m2),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_check_callbacks),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_done_remove),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_invoke),
+	INIT_RCUPREEMPT_PROBE(rcupreempt_trace_next_add)
+};
+
 static void rcupreempt_trace_sum(struct rcupreempt_trace *sp)
 {
 	struct rcupreempt_trace *cp;
@@ -297,9 +350,6 @@ static int rcupreempt_debugfs_init(void)
 	if (!ctrsdir)
 		goto free_out;
 
-	if (!rcu_trace_boost_create(rcudir))
-		goto free_out;
-
 	return 0;
 free_out:
 	if (ctrsdir)
@@ -316,6 +366,21 @@ out:
 static int __init rcupreempt_trace_init(void)
 {
 	int ret;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(rcupreempt_probe_array); i++) {
+		struct rcupreempt_probe_data *p = &rcupreempt_probe_array[i];
+		ret = marker_probe_register(p->name, p->format,
+							p->probe_func, p);
+		if (ret)
+			printk(KERN_INFO "Unable to register rcupreempt \
+				probe %s\n", rcupreempt_probe_array[i].name);
+		ret = marker_arm(p->name);
+		if (ret)
+			printk(KERN_INFO "Unable to arm rcupreempt probe %s\n",
+				p->name);
+	}
+	printk(KERN_INFO "RCU Preempt markers registered\n");
 
 	mutex_init(&rcupreempt_trace_mutex);
 	rcupreempt_trace_buf = kmalloc(RCUPREEMPT_TRACE_BUF_SIZE, GFP_KERNEL);
@@ -329,7 +394,12 @@ static int __init rcupreempt_trace_init(
 
 static void __exit rcupreempt_trace_cleanup(void)
 {
-	rcu_trace_boost_destroy();
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(rcupreempt_probe_array); i++)
+		marker_probe_unregister(rcupreempt_probe_array[i].name);
+	printk(KERN_INFO "RCU Preempt markers unregistered\n");
+
 	debugfs_remove(statdir);
 	debugfs_remove(gpdir);
 	debugfs_remove(ctrsdir);
@@ -337,6 +407,7 @@ static void __exit rcupreempt_trace_clea
 	kfree(rcupreempt_trace_buf);
 }
 
+MODULE_LICENSE("GPL");
 
 module_init(rcupreempt_trace_init);
 module_exit(rcupreempt_trace_cleanup);
Index: linux-2.6.25-rt1/kernel/Kconfig.preempt
===================================================================
--- linux-2.6.25-rt1.orig/kernel/Kconfig.preempt	2008-04-30 14:41:58.000000000 -0400
+++ linux-2.6.25-rt1/kernel/Kconfig.preempt	2008-04-30 14:53:39.000000000 -0400
@@ -81,13 +81,14 @@ config PREEMPT_RCU_BOOST
 	  possible OOM problems.
 
 config RCU_TRACE
-	bool "Enable tracing for RCU - currently stats in debugfs"
+	tristate "Enable tracing for RCU - currently stats in debugfs"
 	depends on PREEMPT_RCU
 	select DEBUG_FS
-	default y
+	select MARKERS
+	default m
 	help
 	  This option provides tracing in RCU which presents stats
 	  in debugfs for debugging RCU implementation.
 
-	  Say Y here if you want to enable RCU tracing
+	  Say Y/M here if you want to enable RCU tracing in-kernel/module.
 	  Say N if you are unsure.
