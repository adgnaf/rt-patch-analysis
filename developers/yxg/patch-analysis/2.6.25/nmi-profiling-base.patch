Subject: [patch] nmi-driven profiling for /proc/profile
From: Ingo Molnar <mingo@elte.hu>

nmi-driven profiling for /proc/profile

Signed-off-by: Ingo Molnar <mingo@elte.hu>
---
 arch/x86/kernel/crash.c   |    8 ----
 arch/x86/kernel/irq_64.c  |    2 +
 arch/x86/kernel/nmi_32.c  |   89 ++++++++++++++++++++++++++++++++++++++++++----
 arch/x86/kernel/nmi_64.c  |   64 +++++++++++++++++++++++++++++++--
 include/asm-x86/apic.h    |    2 +
 include/linux/profile.h   |    1 
 include/linux/sched.h     |    1 
 kernel/profile.c          |    9 +++-
 kernel/time/tick-common.c |    1 
 kernel/time/tick-sched.c  |    2 -
 10 files changed, 155 insertions(+), 24 deletions(-)

Index: linux-2.6.25.4-rt1/arch/x86/kernel/crash.c
===================================================================
--- linux-2.6.25.4-rt1.orig/arch/x86/kernel/crash.c	2008-05-17 08:26:41.000000000 -0400
+++ linux-2.6.25.4-rt1/arch/x86/kernel/crash.c	2008-05-17 08:27:04.000000000 -0400
@@ -78,14 +78,6 @@ static int crash_nmi_callback(struct not
 	return 1;
 }
 
-static void smp_send_nmi_allbutself(void)
-{
-	cpumask_t mask = cpu_online_map;
-	cpu_clear(safe_smp_processor_id(), mask);
-	if (!cpus_empty(mask))
-		send_IPI_mask(mask, NMI_VECTOR);
-}
-
 static struct notifier_block crash_nmi_nb = {
 	.notifier_call = crash_nmi_callback,
 };
Index: linux-2.6.25.4-rt1/arch/x86/kernel/nmi_32.c
===================================================================
--- linux-2.6.25.4-rt1.orig/arch/x86/kernel/nmi_32.c	2008-05-17 08:26:41.000000000 -0400
+++ linux-2.6.25.4-rt1/arch/x86/kernel/nmi_32.c	2008-05-17 08:27:04.000000000 -0400
@@ -25,6 +25,7 @@
 
 #include <asm/smp.h>
 #include <asm/nmi.h>
+#include <asm/mach-default/mach_ipi.h>
 
 #include "mach_traps.h"
 
@@ -42,7 +43,7 @@ static cpumask_t backtrace_mask = CPU_MA
 atomic_t nmi_active = ATOMIC_INIT(0);		/* oprofile uses this */
 
 unsigned int nmi_watchdog = NMI_DEFAULT;
-static unsigned int nmi_hz = HZ;
+static unsigned int nmi_hz = 1000;
 
 static DEFINE_PER_CPU(short, wd_enabled);
 
@@ -92,7 +93,7 @@ static int __init check_nmi_watchdog(voi
 	for_each_possible_cpu(cpu)
 		prev_nmi_count[cpu] = nmi_count(cpu);
 	local_irq_enable();
-	mdelay((20*1000)/nmi_hz); // wait 20 ticks
+	mdelay((100*1000)/nmi_hz); // wait 100 ticks
 
 	for_each_possible_cpu(cpu) {
 #ifdef CONFIG_SMP
@@ -317,6 +318,46 @@ EXPORT_SYMBOL(touch_nmi_watchdog);
 
 extern void die_nmi(struct pt_regs *, const char *msg);
 
+int nmi_show_regs[NR_CPUS];
+
+void nmi_show_all_regs(void)
+{
+	int i;
+
+	if (system_state == SYSTEM_BOOTING)
+		return;
+
+	printk(KERN_WARNING "nmi_show_all_regs(): start on CPU#%d.\n",
+		raw_smp_processor_id());
+	dump_stack();
+
+	for_each_online_cpu(i)
+		nmi_show_regs[i] = 1;
+
+	smp_send_nmi_allbutself();
+
+	for_each_online_cpu(i) {
+		while (nmi_show_regs[i] == 1)
+			barrier();
+	}
+}
+
+static DEFINE_SPINLOCK(nmi_print_lock);
+
+void irq_show_regs_callback(int cpu, struct pt_regs *regs)
+{
+	if (!nmi_show_regs[cpu])
+		return;
+
+	nmi_show_regs[cpu] = 0;
+	spin_lock(&nmi_print_lock);
+	printk(KERN_WARNING "NMI show regs on CPU#%d:\n", cpu);
+	printk(KERN_WARNING "apic_timer_irqs: %d\n",
+		per_cpu(irq_stat, cpu).apic_timer_irqs);
+	show_regs(regs);
+	spin_unlock(&nmi_print_lock);
+}
+
 __kprobes int nmi_watchdog_tick(struct pt_regs * regs, unsigned reason)
 {
 
@@ -330,6 +371,8 @@ __kprobes int nmi_watchdog_tick(struct p
 	int cpu = smp_processor_id();
 	int rc = 0;
 
+	__profile_tick(CPU_PROFILING, regs);
+
 	/* check for other users first */
 	if (notify_die(DIE_NMI, "nmi", regs, reason, 2, SIGINT)
 			== NOTIFY_STOP) {
@@ -354,6 +397,9 @@ __kprobes int nmi_watchdog_tick(struct p
 	sum = per_cpu(irq_stat, cpu).apic_timer_irqs +
 		per_cpu(irq_stat, cpu).irq0_irqs;
 
+	irq_show_regs_callback(cpu, regs);
+
+	/* if the apic timer isn't firing, this cpu isn't doing much */
 	/* if the none of the timers isn't firing, this cpu isn't doing much */
 	if (!touched && last_irq_sums[cpu] == sum) {
 		/*
@@ -361,11 +407,30 @@ __kprobes int nmi_watchdog_tick(struct p
 		 * wait a few IRQs (5 seconds) before doing the oops ...
 		 */
 		alert_counter[cpu]++;
-		if (alert_counter[cpu] == 5*nmi_hz)
-			/*
-			 * die_nmi will return ONLY if NOTIFY_STOP happens..
-			 */
-			die_nmi(regs, "BUG: NMI Watchdog detected LOCKUP");
+		if (alert_counter[cpu] && !(alert_counter[cpu] % (5*nmi_hz))) {
+			int i;
+
+			spin_lock(&nmi_print_lock);
+			printk(KERN_WARNING "NMI watchdog detected lockup on "
+				"CPU#%d (%d/%d)\n", cpu, alert_counter[cpu],
+						    5*nmi_hz);
+			show_regs(regs);
+			spin_unlock(&nmi_print_lock);
+
+			for_each_online_cpu(i) {
+				if (i == cpu)
+					continue;
+				nmi_show_regs[i] = 1;
+				while (nmi_show_regs[i] == 1)
+					cpu_relax();
+			}
+			printk(KERN_WARNING "NMI watchdog running again ...\n");
+			for_each_online_cpu(i)
+				alert_counter[i] = 0;
+
+
+		}
+
 	} else {
 		last_irq_sums[cpu] = sum;
 		alert_counter[cpu] = 0;
@@ -463,5 +528,15 @@ void __trigger_all_cpu_backtrace(void)
 	}
 }
 
+void smp_send_nmi_allbutself(void)
+{
+#ifdef CONFIG_SMP
+	cpumask_t mask = cpu_online_map;
+	cpu_clear(safe_smp_processor_id(), mask);
+	if (!cpus_empty(mask))
+		send_IPI_mask(mask, NMI_VECTOR);
+#endif
+}
+
 EXPORT_SYMBOL(nmi_active);
 EXPORT_SYMBOL(nmi_watchdog);
Index: linux-2.6.25.4-rt1/arch/x86/kernel/irq_64.c
===================================================================
--- linux-2.6.25.4-rt1.orig/arch/x86/kernel/irq_64.c	2008-05-17 08:26:54.000000000 -0400
+++ linux-2.6.25.4-rt1/arch/x86/kernel/irq_64.c	2008-05-17 08:27:04.000000000 -0400
@@ -166,6 +166,8 @@ asmlinkage unsigned int do_IRQ(struct pt
 	unsigned vector = ~regs->orig_ax;
 	unsigned irq;
 
+	irq_show_regs_callback(smp_processor_id(), regs);
+
 	exit_idle();
 	irq_enter();
 	irq = __get_cpu_var(vector_irq)[vector];
Index: linux-2.6.25.4-rt1/arch/x86/kernel/nmi_64.c
===================================================================
--- linux-2.6.25.4-rt1.orig/arch/x86/kernel/nmi_64.c	2008-05-17 08:26:41.000000000 -0400
+++ linux-2.6.25.4-rt1/arch/x86/kernel/nmi_64.c	2008-05-17 08:27:04.000000000 -0400
@@ -20,11 +20,13 @@
 #include <linux/kprobes.h>
 #include <linux/cpumask.h>
 #include <linux/kdebug.h>
+#include <linux/kernel_stat.h>
 
 #include <asm/smp.h>
 #include <asm/nmi.h>
 #include <asm/proto.h>
 #include <asm/mce.h>
+#include <asm/mach_apic.h>
 
 int unknown_nmi_panic;
 int nmi_watchdog_enabled;
@@ -42,7 +44,7 @@ atomic_t nmi_active = ATOMIC_INIT(0);		/
 static int panic_on_timeout;
 
 unsigned int nmi_watchdog = NMI_DEFAULT;
-static unsigned int nmi_hz = HZ;
+static unsigned int nmi_hz = 1000;
 
 static DEFINE_PER_CPU(short, wd_enabled);
 
@@ -297,7 +299,7 @@ void touch_nmi_watchdog(void)
 		unsigned cpu;
 
 		/*
- 		 * Tell other CPUs to reset their alert counters. We cannot
+		 * Tell other CPUs to reset their alert counters. We cannot
 		 * do it ourselves because the alert count increase is not
 		 * atomic.
 		 */
@@ -311,6 +313,41 @@ void touch_nmi_watchdog(void)
 }
 EXPORT_SYMBOL(touch_nmi_watchdog);
 
+int nmi_show_regs[NR_CPUS];
+
+void nmi_show_all_regs(void)
+{
+	int i;
+
+	if (system_state == SYSTEM_BOOTING)
+		return;
+
+	smp_send_nmi_allbutself();
+
+	for_each_online_cpu(i)
+		nmi_show_regs[i] = 1;
+
+	for_each_online_cpu(i) {
+		while (nmi_show_regs[i] == 1)
+			barrier();
+	}
+}
+
+static DEFINE_SPINLOCK(nmi_print_lock);
+
+void irq_show_regs_callback(int cpu, struct pt_regs *regs)
+{
+	if (!nmi_show_regs[cpu])
+		return;
+
+	nmi_show_regs[cpu] = 0;
+	spin_lock(&nmi_print_lock);
+	printk(KERN_WARNING "NMI show regs on CPU#%d:\n", cpu);
+	printk(KERN_WARNING "apic_timer_irqs: %d\n", read_pda(apic_timer_irqs));
+	show_regs(regs);
+	spin_unlock(&nmi_print_lock);
+}
+
 int __kprobes nmi_watchdog_tick(struct pt_regs * regs, unsigned reason)
 {
 	int sum;
@@ -318,6 +355,9 @@ int __kprobes nmi_watchdog_tick(struct p
 	int cpu = smp_processor_id();
 	int rc = 0;
 
+	irq_show_regs_callback(cpu, regs);
+	__profile_tick(CPU_PROFILING, regs);
+
 	/* check for other users first */
 	if (notify_die(DIE_NMI, "nmi", regs, reason, 2, SIGINT)
 			== NOTIFY_STOP) {
@@ -354,9 +394,20 @@ int __kprobes nmi_watchdog_tick(struct p
 		 * wait a few IRQs (5 seconds) before doing the oops ...
 		 */
 		local_inc(&__get_cpu_var(alert_counter));
-		if (local_read(&__get_cpu_var(alert_counter)) == 5*nmi_hz)
+		if (local_read(&__get_cpu_var(alert_counter)) == 5*nmi_hz) {
+			int i;
+
+			for_each_online_cpu(i) {
+				if (i == cpu)
+					continue;
+				nmi_show_regs[i] = 1;
+				while (nmi_show_regs[i] == 1)
+					cpu_relax();
+			}
+
 			die_nmi("NMI Watchdog detected LOCKUP on CPU %d\n", regs,
 				panic_on_timeout);
+		}
 	} else {
 		__get_cpu_var(last_irq_sum) = sum;
 		local_set(&__get_cpu_var(alert_counter), 0);
@@ -474,5 +525,12 @@ void __trigger_all_cpu_backtrace(void)
 	}
 }
 
+void smp_send_nmi_allbutself(void)
+{
+#ifdef CONFIG_SMP
+	send_IPI_allbutself(NMI_VECTOR);
+#endif
+}
+
 EXPORT_SYMBOL(nmi_active);
 EXPORT_SYMBOL(nmi_watchdog);
Index: linux-2.6.25.4-rt1/include/asm-x86/apic.h
===================================================================
--- linux-2.6.25.4-rt1.orig/include/asm-x86/apic.h	2008-05-17 08:26:41.000000000 -0400
+++ linux-2.6.25.4-rt1/include/asm-x86/apic.h	2008-05-17 08:27:04.000000000 -0400
@@ -137,4 +137,6 @@ static inline void lapic_shutdown(void) 
 
 #endif /* !CONFIG_X86_LOCAL_APIC */
 
+extern void smp_send_nmi_allbutself(void);
+
 #endif /* __ASM_APIC_H */
Index: linux-2.6.25.4-rt1/include/linux/profile.h
===================================================================
--- linux-2.6.25.4-rt1.orig/include/linux/profile.h	2008-05-17 08:26:41.000000000 -0400
+++ linux-2.6.25.4-rt1/include/linux/profile.h	2008-05-17 08:27:04.000000000 -0400
@@ -23,6 +23,7 @@ struct notifier_block;
 
 /* init basic kernel profiler */
 void __init profile_init(void);
+void __profile_tick(int type, struct pt_regs *regs);
 void profile_tick(int);
 
 /*
Index: linux-2.6.25.4-rt1/kernel/profile.c
===================================================================
--- linux-2.6.25.4-rt1.orig/kernel/profile.c	2008-05-17 08:26:41.000000000 -0400
+++ linux-2.6.25.4-rt1/kernel/profile.c	2008-05-17 08:27:04.000000000 -0400
@@ -408,16 +408,19 @@ void profile_hits(int type, void *__pc, 
 #endif /* !CONFIG_SMP */
 EXPORT_SYMBOL_GPL(profile_hits);
 
-void profile_tick(int type)
+void __profile_tick(int type, struct pt_regs *regs)
 {
-	struct pt_regs *regs = get_irq_regs();
-
 	if (type == CPU_PROFILING && timer_hook)
 		timer_hook(regs);
 	if (!user_mode(regs) && cpu_isset(smp_processor_id(), prof_cpu_mask))
 		profile_hit(type, (void *)profile_pc(regs));
 }
 
+void profile_tick(int type)
+{
+	return __profile_tick(type, get_irq_regs());
+}
+
 #ifdef CONFIG_PROC_FS
 #include <linux/proc_fs.h>
 #include <asm/uaccess.h>
Index: linux-2.6.25.4-rt1/kernel/time/tick-common.c
===================================================================
--- linux-2.6.25.4-rt1.orig/kernel/time/tick-common.c	2008-05-17 08:26:41.000000000 -0400
+++ linux-2.6.25.4-rt1/kernel/time/tick-common.c	2008-05-17 08:27:04.000000000 -0400
@@ -68,7 +68,6 @@ static void tick_periodic(int cpu)
 	}
 
 	update_process_times(user_mode(get_irq_regs()));
-	profile_tick(CPU_PROFILING);
 }
 
 /*
Index: linux-2.6.25.4-rt1/kernel/time/tick-sched.c
===================================================================
--- linux-2.6.25.4-rt1.orig/kernel/time/tick-sched.c	2008-05-17 08:26:41.000000000 -0400
+++ linux-2.6.25.4-rt1/kernel/time/tick-sched.c	2008-05-17 08:27:04.000000000 -0400
@@ -476,7 +476,6 @@ static void tick_nohz_handler(struct clo
 	}
 
 	update_process_times(user_mode(regs));
-	profile_tick(CPU_PROFILING);
 
 	/* Do not restart, when we are in the idle loop */
 	if (ts->tick_stopped)
@@ -583,7 +582,6 @@ static enum hrtimer_restart tick_sched_t
 			ts->idle_jiffies++;
 		}
 		update_process_times(user_mode(regs));
-		profile_tick(CPU_PROFILING);
 	}
 
 	/* Do not restart, when we are in the idle loop */
Index: linux-2.6.25.4-rt1/include/linux/sched.h
===================================================================
--- linux-2.6.25.4-rt1.orig/include/linux/sched.h	2008-05-17 08:26:56.000000000 -0400
+++ linux-2.6.25.4-rt1/include/linux/sched.h	2008-05-17 08:27:04.000000000 -0400
@@ -271,6 +271,7 @@ static inline void show_state(void)
 }
 
 extern void show_regs(struct pt_regs *);
+extern void irq_show_regs_callback(int cpu, struct pt_regs *regs);
 
 /*
  * TASK is a pointer to the task whose backtrace we want to see (or NULL for current
