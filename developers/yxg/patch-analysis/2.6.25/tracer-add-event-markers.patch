Add markers to various events

This patch adds markers to various events in the kernel.
(interrupts, task activation and hrtimers)

Signed-off-by: Steven Rostedt <srostedt@redhat.com>
---
 arch/x86/kernel/apic_32.c  |    2 +
 arch/x86/kernel/irq_32.c   |    3 ++
 arch/x86/kernel/irq_64.c   |    3 ++
 arch/x86/kernel/traps_32.c |    4 +++
 arch/x86/kernel/traps_64.c |    4 +++
 arch/x86/mm/fault.c        |    3 ++
 include/linux/ftrace.h     |   55 +++++++++++++++++++++++++++++++++++++++++++++
 kernel/hrtimer.c           |    6 ++++
 kernel/sched.c             |    7 +++++
 9 files changed, 87 insertions(+)

Index: linux-2.6.25.4-rt1/arch/x86/kernel/apic_32.c
===================================================================
--- linux-2.6.25.4-rt1.orig/arch/x86/kernel/apic_32.c	2008-05-17 08:26:45.000000000 -0400
+++ linux-2.6.25.4-rt1/arch/x86/kernel/apic_32.c	2008-05-17 08:26:54.000000000 -0400
@@ -28,6 +28,7 @@
 #include <linux/acpi_pmtmr.h>
 #include <linux/module.h>
 #include <linux/dmi.h>
+#include <linux/ftrace.h>
 
 #include <asm/atomic.h>
 #include <asm/smp.h>
@@ -598,6 +599,7 @@ void smp_apic_timer_interrupt(struct pt_
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
+	ftrace_event_irq(-1, user_mode(regs), regs->ip);
 	/*
 	 * NOTE! We'd better ACK the irq immediately,
 	 * because timer handling can be slow.
Index: linux-2.6.25.4-rt1/arch/x86/kernel/irq_32.c
===================================================================
--- linux-2.6.25.4-rt1.orig/arch/x86/kernel/irq_32.c	2008-05-17 08:26:45.000000000 -0400
+++ linux-2.6.25.4-rt1/arch/x86/kernel/irq_32.c	2008-05-17 08:26:54.000000000 -0400
@@ -16,6 +16,8 @@
 #include <linux/cpu.h>
 #include <linux/delay.h>
 
+#include <linux/ftrace.h>
+
 #include <asm/apic.h>
 #include <asm/uaccess.h>
 
@@ -85,6 +87,7 @@ unsigned int do_IRQ(struct pt_regs *regs
 
 	old_regs = set_irq_regs(regs);
 	irq_enter();
+	ftrace_event_irq(irq, user_mode(regs), regs->ip);
 #ifdef CONFIG_DEBUG_STACKOVERFLOW
 	/* Debugging check for stack overflow: is there less than 1KB free? */
 	{
Index: linux-2.6.25.4-rt1/arch/x86/kernel/irq_64.c
===================================================================
--- linux-2.6.25.4-rt1.orig/arch/x86/kernel/irq_64.c	2008-05-17 08:26:45.000000000 -0400
+++ linux-2.6.25.4-rt1/arch/x86/kernel/irq_64.c	2008-05-17 08:26:54.000000000 -0400
@@ -17,6 +17,7 @@
 #include <asm/io_apic.h>
 #include <asm/idle.h>
 #include <asm/smp.h>
+#include <linux/ftrace.h>
 
 atomic_t irq_err_count;
 
@@ -169,6 +170,8 @@ asmlinkage unsigned int do_IRQ(struct pt
 	irq_enter();
 	irq = __get_cpu_var(vector_irq)[vector];
 
+	ftrace_event_irq(irq, user_mode(regs), regs->ip);
+
 #ifdef CONFIG_DEBUG_STACKOVERFLOW
 	stack_overflow_check(regs);
 #endif
Index: linux-2.6.25.4-rt1/arch/x86/kernel/traps_32.c
===================================================================
--- linux-2.6.25.4-rt1.orig/arch/x86/kernel/traps_32.c	2008-05-17 08:26:45.000000000 -0400
+++ linux-2.6.25.4-rt1/arch/x86/kernel/traps_32.c	2008-05-17 08:26:54.000000000 -0400
@@ -30,6 +30,8 @@
 #include <linux/nmi.h>
 #include <linux/bug.h>
 
+#include <linux/ftrace.h>
+
 #ifdef CONFIG_EISA
 #include <linux/ioport.h>
 #include <linux/eisa.h>
@@ -804,6 +806,8 @@ __kprobes void do_nmi(struct pt_regs * r
 
 	nmi_enter();
 
+	ftrace_event_irq(-1, user_mode(regs), regs->ip);
+
 	cpu = smp_processor_id();
 
 	++nmi_count(cpu);
Index: linux-2.6.25.4-rt1/arch/x86/kernel/traps_64.c
===================================================================
--- linux-2.6.25.4-rt1.orig/arch/x86/kernel/traps_64.c	2008-05-17 08:26:45.000000000 -0400
+++ linux-2.6.25.4-rt1/arch/x86/kernel/traps_64.c	2008-05-17 08:26:54.000000000 -0400
@@ -33,6 +33,8 @@
 #include <linux/kdebug.h>
 #include <linux/utsname.h>
 
+#include <linux/ftrace.h>
+
 #if defined(CONFIG_EDAC)
 #include <linux/edac.h>
 #endif
@@ -825,6 +827,8 @@ asmlinkage __kprobes void default_do_nmi
 
 	cpu = smp_processor_id();
 
+	ftrace_event_irq(-1, user_mode(regs), regs->ip);
+
 	/* Only the BSP gets external NMIs from the system.  */
 	if (!cpu)
 		reason = get_nmi_reason();
Index: linux-2.6.25.4-rt1/arch/x86/mm/fault.c
===================================================================
--- linux-2.6.25.4-rt1.orig/arch/x86/mm/fault.c	2008-05-17 08:26:45.000000000 -0400
+++ linux-2.6.25.4-rt1/arch/x86/mm/fault.c	2008-05-17 08:26:54.000000000 -0400
@@ -25,6 +25,7 @@
 #include <linux/kprobes.h>
 #include <linux/uaccess.h>
 #include <linux/kdebug.h>
+#include <linux/ftrace.h>
 
 #include <asm/system.h>
 #include <asm/desc.h>
@@ -597,6 +598,8 @@ void __kprobes do_page_fault(struct pt_r
 	/* get the address */
 	address = read_cr2();
 
+	ftrace_event_fault(regs->ip, error_code, address);
+
 	si_code = SEGV_MAPERR;
 
 	if (notify_page_fault(regs))
Index: linux-2.6.25.4-rt1/kernel/hrtimer.c
===================================================================
--- linux-2.6.25.4-rt1.orig/kernel/hrtimer.c	2008-05-17 08:26:45.000000000 -0400
+++ linux-2.6.25.4-rt1/kernel/hrtimer.c	2008-05-17 08:26:54.000000000 -0400
@@ -44,6 +44,8 @@
 #include <linux/seq_file.h>
 #include <linux/err.h>
 
+#include <linux/ftrace.h>
+
 #include <asm/uaccess.h>
 
 /**
@@ -735,6 +737,7 @@ static void enqueue_hrtimer(struct hrtim
 	struct hrtimer *entry;
 	int leftmost = 1;
 
+	ftrace_event_timer(&timer->expires, timer);
 	/*
 	 * Find the right place in the rbtree:
 	 */
@@ -1169,6 +1172,7 @@ void hrtimer_interrupt(struct clock_even
 
  retry:
 	now = ktime_get();
+	ftrace_event_timestamp(&now);
 
 	expires_next.tv64 = KTIME_MAX;
 
@@ -1207,6 +1211,8 @@ void hrtimer_interrupt(struct clock_even
 				continue;
 			}
 
+			ftrace_event_timer(&timer->expires, timer);
+
 			__run_hrtimer(timer);
 		}
 		spin_unlock(&cpu_base->lock);
Index: linux-2.6.25.4-rt1/kernel/sched.c
===================================================================
--- linux-2.6.25.4-rt1.orig/kernel/sched.c	2008-05-17 08:26:54.000000000 -0400
+++ linux-2.6.25.4-rt1/kernel/sched.c	2008-05-17 08:26:54.000000000 -0400
@@ -82,6 +82,11 @@
 #define PRIO_TO_NICE(prio)	((prio) - MAX_RT_PRIO - 20)
 #define TASK_NICE(p)		PRIO_TO_NICE((p)->static_prio)
 
+#define __PRIO(prio) \
+	((prio) <= 99 ? 199 - (prio) : (prio) - 120)
+
+#define PRIO(p) __PRIO((p)->prio)
+
 /*
  * 'User priority' is the nice value converted to something we
  * can work with better when scaling various scheduler parameters,
@@ -1346,6 +1351,7 @@ static void activate_task(struct rq *rq,
 	if (task_contributes_to_load(p))
 		rq->nr_uninterruptible--;
 
+	ftrace_event_task(p->pid, PRIO(p), rq->nr_running);
 	enqueue_task(rq, p, wakeup);
 	inc_nr_running(p, rq);
 }
@@ -1358,6 +1364,7 @@ static void deactivate_task(struct rq *r
 	if (task_contributes_to_load(p))
 		rq->nr_uninterruptible++;
 
+	ftrace_event_task(p->pid, PRIO(p), rq->nr_running);
 	dequeue_task(rq, p, sleep);
 	dec_nr_running(p, rq);
 }
Index: linux-2.6.25.4-rt1/include/linux/ftrace.h
===================================================================
--- linux-2.6.25.4-rt1.orig/include/linux/ftrace.h	2008-05-17 08:26:52.000000000 -0400
+++ linux-2.6.25.4-rt1/include/linux/ftrace.h	2008-05-17 08:26:54.000000000 -0400
@@ -4,6 +4,7 @@
 #ifdef CONFIG_FTRACE
 
 #include <linux/linkage.h>
+#include <linux/ktime.h>
 
 extern int ftrace_enabled;
 extern int
@@ -120,4 +121,58 @@ static inline void tracer_disable(void)
 # define trace_preempt_off(a0, a1)		do { } while (0)
 #endif
 
+#ifdef CONFIG_EVENT_TRACER
+extern int ftrace_events_enabled;
+enum ftrace_event_enum {
+	FTRACE_EVENTS_IRQ,
+	FTRACE_EVENTS_FAULT,
+	FTRACE_EVENTS_TIMER,
+	FTRACE_EVENTS_TIMESTAMP,
+	FTRACE_EVENTS_TASK,
+};
+extern void ftrace_record_event(enum ftrace_event_enum event, ...);
+static inline void ftrace_event_irq(int irq, int user, unsigned long ip)
+{
+	if (unlikely(ftrace_events_enabled))
+		ftrace_record_event(FTRACE_EVENTS_IRQ,
+				    irq, user, ip);
+}
+
+static inline void ftrace_event_fault(unsigned long ip, unsigned long error,
+				      unsigned long addr)
+{
+	if (unlikely(ftrace_events_enabled))
+		ftrace_record_event(FTRACE_EVENTS_FAULT,
+				    ip, error, addr);
+}
+
+static inline void ftrace_event_timer(void *p1, void *p2)
+{
+	if (unlikely(ftrace_events_enabled))
+		ftrace_record_event(FTRACE_EVENTS_TIMER,
+				    p1, p2);
+}
+
+static inline void ftrace_event_timestamp(ktime_t *time)
+{
+	if (unlikely(ftrace_events_enabled))
+		ftrace_record_event(FTRACE_EVENTS_TIMESTAMP,
+				    time);
+}
+
+static inline void ftrace_event_task(pid_t pid, int prio,
+				     unsigned long  running)
+{
+	if (unlikely(ftrace_events_enabled))
+		ftrace_record_event(FTRACE_EVENTS_TASK,
+				    pid, prio, running);
+}
+#else
+# define ftrace_event_irq(irq, user, ip)	do { } while (0)
+# define ftrace_event_fault(ip, error, addr)	do { } while (0)
+# define ftrace_event_timer(p1, p2)		do { } while (0)
+# define ftrace_event_timestamp(now)		do { } while (0)
+# define ftrace_event_task(pid, prio, running)	do { } while (0)
+#endif /* CONFIG_TRACE_EVENTS */
+
 #endif /* _LINUX_FTRACE_H */
