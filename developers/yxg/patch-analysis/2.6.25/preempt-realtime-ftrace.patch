---
 kernel/trace/ftrace.c             |    4 ++--
 kernel/trace/trace.c              |    2 +-
 kernel/trace/trace_hist.c         |    2 +-
 kernel/trace/trace_irqsoff.c      |    2 +-
 kernel/trace/trace_sched_wakeup.c |    2 +-
 5 files changed, 6 insertions(+), 6 deletions(-)

Index: linux-2.6.25.4-rt1/kernel/trace/ftrace.c
===================================================================
--- linux-2.6.25.4-rt1.orig/kernel/trace/ftrace.c	2008-05-17 08:26:52.000000000 -0400
+++ linux-2.6.25.4-rt1/kernel/trace/ftrace.c	2008-05-17 08:27:24.000000000 -0400
@@ -39,7 +39,7 @@ static int last_ftrace_enabled;
  */
 static int ftrace_disabled __read_mostly;
 
-static DEFINE_SPINLOCK(ftrace_lock);
+static DEFINE_RAW_SPINLOCK(ftrace_lock);
 static DEFINE_MUTEX(ftrace_sysctl_lock);
 
 static struct ftrace_ops ftrace_list_end __read_mostly =
@@ -171,7 +171,7 @@ static struct hlist_head ftrace_hash[FTR
 
 static DEFINE_PER_CPU(int, ftrace_shutdown_disable_cpu);
 
-static DEFINE_SPINLOCK(ftrace_shutdown_lock);
+static DEFINE_RAW_SPINLOCK(ftrace_shutdown_lock);
 static DEFINE_MUTEX(ftraced_lock);
 static DEFINE_MUTEX(ftrace_filter_lock);
 
Index: linux-2.6.25.4-rt1/kernel/trace/trace_sched_wakeup.c
===================================================================
--- linux-2.6.25.4-rt1.orig/kernel/trace/trace_sched_wakeup.c	2008-05-17 08:26:55.000000000 -0400
+++ linux-2.6.25.4-rt1/kernel/trace/trace_sched_wakeup.c	2008-05-17 08:27:24.000000000 -0400
@@ -26,7 +26,7 @@ static struct task_struct	*wakeup_task;
 static int			wakeup_cpu;
 static unsigned			wakeup_prio = -1;
 
-static DEFINE_SPINLOCK(wakeup_lock);
+static DEFINE_RAW_SPINLOCK(wakeup_lock);
 
 static void __wakeup_reset(struct trace_array *tr);
 
Index: linux-2.6.25.4-rt1/kernel/trace/trace.c
===================================================================
--- linux-2.6.25.4-rt1.orig/kernel/trace/trace.c	2008-05-17 08:27:15.000000000 -0400
+++ linux-2.6.25.4-rt1/kernel/trace/trace.c	2008-05-17 08:27:24.000000000 -0400
@@ -626,7 +626,7 @@ static unsigned map_pid_to_cmdline[PID_M
 static unsigned map_cmdline_to_pid[SAVED_CMDLINES];
 static char saved_cmdlines[SAVED_CMDLINES][TASK_COMM_LEN];
 static int cmdline_idx;
-static DEFINE_SPINLOCK(trace_cmdline_lock);
+static DEFINE_RAW_SPINLOCK(trace_cmdline_lock);
 
 /* trace in all context switches */
 atomic_t trace_record_cmdline_enabled __read_mostly;
Index: linux-2.6.25.4-rt1/kernel/trace/trace_hist.c
===================================================================
--- linux-2.6.25.4-rt1.orig/kernel/trace/trace_hist.c	2008-05-17 08:26:55.000000000 -0400
+++ linux-2.6.25.4-rt1/kernel/trace/trace_hist.c	2008-05-17 08:27:24.000000000 -0400
@@ -405,7 +405,7 @@ int tracing_wakeup_hist __read_mostly = 
 static unsigned wakeup_prio = (unsigned)-1 ;
 static struct task_struct *wakeup_task;
 static cycle_t wakeup_start;
-static DEFINE_SPINLOCK(wakeup_lock);
+static DEFINE_RAW_SPINLOCK(wakeup_lock);
 
 void tracing_hist_wakeup_start(struct task_struct *p,
 			       struct task_struct *curr)
Index: linux-2.6.25.4-rt1/kernel/trace/trace_irqsoff.c
===================================================================
--- linux-2.6.25.4-rt1.orig/kernel/trace/trace_irqsoff.c	2008-05-17 08:26:55.000000000 -0400
+++ linux-2.6.25.4-rt1/kernel/trace/trace_irqsoff.c	2008-05-17 08:27:24.000000000 -0400
@@ -24,7 +24,7 @@ static int				tracer_enabled __read_most
 
 static DEFINE_PER_CPU(int, tracing_cpu);
 
-static DEFINE_SPINLOCK(max_trace_lock);
+static DEFINE_RAW_SPINLOCK(max_trace_lock);
 
 enum {
 	TRACER_IRQS_OFF		= (1 << 1),
