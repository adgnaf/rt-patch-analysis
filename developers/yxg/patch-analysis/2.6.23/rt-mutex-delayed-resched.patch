---
 drivers/acpi/processor_idle.c |    6 +++---
 include/linux/preempt.h       |   16 ++++++++++++++++
 include/linux/sched.h         |   23 ++++++++++++++++++++++-
 kernel/sched.c                |   10 +++++++---
 4 files changed, 48 insertions(+), 7 deletions(-)

Index: linux-2.6.23-rt1/drivers/acpi/processor_idle.c
===================================================================
--- linux-2.6.23-rt1.orig/drivers/acpi/processor_idle.c	2007-10-11 16:00:08.000000000 -0400
+++ linux-2.6.23-rt1/drivers/acpi/processor_idle.c	2007-10-11 16:00:26.000000000 -0400
@@ -809,7 +809,7 @@ static int acpi_idle_enter_c1(struct cpu
 	 * NEED_RESCHED:
 	 */
 	smp_mb();
-	if (!need_resched())
+	if (!need_resched() || !need_resched_delayed())
 		safe_halt();
 	current_thread_info()->status |= TS_POLLING;
 
@@ -846,7 +846,7 @@ static int acpi_idle_enter_simple(struct
 	 */
 	smp_mb();
 
-	if (unlikely(need_resched())) {
+	if (unlikely(need_resched() || need_resched_delayed())) {
 		current_thread_info()->status |= TS_POLLING;
 		local_irq_enable();
 		return 0;
@@ -917,7 +917,7 @@ static int acpi_idle_enter_bm(struct cpu
 	 */
 	smp_mb();
 
-	if (unlikely(need_resched())) {
+	if (unlikely(need_resched() || need_resched_delayed())) {
 		current_thread_info()->status |= TS_POLLING;
 		local_irq_enable();
 		return 0;
Index: linux-2.6.23-rt1/include/linux/preempt.h
===================================================================
--- linux-2.6.23-rt1.orig/include/linux/preempt.h	2007-10-11 16:00:25.000000000 -0400
+++ linux-2.6.23-rt1/include/linux/preempt.h	2007-10-11 16:00:26.000000000 -0400
@@ -68,6 +68,21 @@ do { \
 		preempt_schedule(); \
 } while (0)
 
+
+/*
+ * If the architecture doens't have TIF_NEED_RESCHED_DELAYED
+ * help it out and define it back to TIF_NEED_RESCHED
+ */
+#ifndef TIF_NEED_RESCHED_DELAYED
+# define TIF_NEED_RESCHED_DELAYED TIF_NEED_RESCHED
+#endif
+
+#define preempt_check_resched_delayed() \
+do { \
+	if (unlikely(test_thread_flag(TIF_NEED_RESCHED_DELAYED))) \
+		preempt_schedule(); \
+} while (0)
+
 #define preempt_enable() \
 do { \
 	__preempt_enable_no_resched(); \
@@ -82,6 +97,7 @@ do { \
 #define __preempt_enable_no_resched()	do { } while (0)
 #define preempt_enable()		do { } while (0)
 #define preempt_check_resched()		do { } while (0)
+#define preempt_check_resched_delayed()	do { } while (0)
 
 #define preempt_schedule_irq()		do { } while (0)
 
Index: linux-2.6.23-rt1/include/linux/sched.h
===================================================================
--- linux-2.6.23-rt1.orig/include/linux/sched.h	2007-10-11 16:00:20.000000000 -0400
+++ linux-2.6.23-rt1/include/linux/sched.h	2007-10-11 16:00:26.000000000 -0400
@@ -1882,11 +1882,32 @@ static inline int signal_pending(struct 
 	return unlikely(test_tsk_thread_flag(p,TIF_SIGPENDING));
 }
   
-static inline int need_resched(void)
+static inline int _need_resched(void)
 {
 	return unlikely(test_thread_flag(TIF_NEED_RESCHED));
 }
 
+static inline int need_resched(void)
+{
+	touch_critical_timing();
+	return _need_resched();
+}
+
+static inline void set_tsk_need_resched_delayed(struct task_struct *tsk)
+{
+	set_tsk_thread_flag(tsk,TIF_NEED_RESCHED_DELAYED);
+}
+
+static inline void clear_tsk_need_resched_delayed(struct task_struct *tsk)
+{
+	clear_tsk_thread_flag(tsk,TIF_NEED_RESCHED_DELAYED);
+}
+
+static inline int need_resched_delayed(void)
+{
+	return unlikely(test_thread_flag(TIF_NEED_RESCHED_DELAYED));
+}
+
 /*
  * cond_resched() and cond_resched_lock(): latency reduction via
  * explicit rescheduling in places that are safe. The return
Index: linux-2.6.23-rt1/kernel/sched.c
===================================================================
--- linux-2.6.23-rt1.orig/kernel/sched.c	2007-10-11 16:00:25.000000000 -0400
+++ linux-2.6.23-rt1/kernel/sched.c	2007-10-11 16:00:26.000000000 -0400
@@ -3467,6 +3467,7 @@ need_resched_nonpreemptible:
 
 	spin_lock_irq(&rq->lock);
 	clear_tsk_need_resched(prev);
+	clear_tsk_need_resched_delayed(prev);
 	__update_rq_clock(rq);
 
 	if (prev->state && !(preempt_count() & PREEMPT_ACTIVE)) {
@@ -3504,7 +3505,8 @@ need_resched_nonpreemptible:
 		goto need_resched_nonpreemptible;
 	}
 	__preempt_enable_no_resched();
-	if (unlikely(test_thread_flag(TIF_NEED_RESCHED)))
+	if (unlikely(test_thread_flag(TIF_NEED_RESCHED) ||
+		     test_thread_flag(TIF_NEED_RESCHED_DELAYED)))
 		goto need_resched;
 }
 EXPORT_SYMBOL(schedule);
@@ -3548,7 +3550,8 @@ need_resched:
 
 	/* we could miss a preemption opportunity between schedule and now */
 	barrier();
-	if (unlikely(test_thread_flag(TIF_NEED_RESCHED)))
+	if (unlikely(test_thread_flag(TIF_NEED_RESCHED) ||
+			test_thread_flag(TIF_NEED_RESCHED_DELAYED)))
 		goto need_resched;
 }
 EXPORT_SYMBOL(preempt_schedule);
@@ -3590,7 +3593,8 @@ need_resched:
 
 	/* we could miss a preemption opportunity between schedule and now */
 	barrier();
-	if (unlikely(test_thread_flag(TIF_NEED_RESCHED)))
+	if (unlikely(test_thread_flag(TIF_NEED_RESCHED) ||
+		     test_thread_flag(TIF_NEED_RESCHED_DELAYED)))
 		goto need_resched;
 }
 
