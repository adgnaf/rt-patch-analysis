---
 arch/i386/kernel/kprobes.c   |    5 ++---
 arch/x86_64/kernel/kprobes.c |    4 +---
 include/linux/netpoll.h      |    2 +-
 kernel/hrtimer.c             |    4 +++-
 kernel/workqueue.c           |    2 +-
 5 files changed, 8 insertions(+), 9 deletions(-)

Index: linux-2.6.23-rt1/arch/i386/kernel/kprobes.c
===================================================================
--- linux-2.6.23-rt1.orig/arch/i386/kernel/kprobes.c	2007-10-11 15:59:57.000000000 -0400
+++ linux-2.6.23-rt1/arch/i386/kernel/kprobes.c	2007-10-11 16:01:16.000000000 -0400
@@ -662,12 +662,11 @@ int __kprobes kprobe_exceptions_notify(s
 		break;
 	case DIE_GPF:
 	case DIE_PAGE_FAULT:
+		// TODO: do this better on PREEMPT_RT
 		/* kprobe_running() needs smp_processor_id() */
-		preempt_disable();
-		if (kprobe_running() &&
+		if (per_cpu(current_kprobe, raw_smp_processor_id()) &&
 		    kprobe_fault_handler(args->regs, args->trapnr))
 			ret = NOTIFY_STOP;
-		preempt_enable();
 		break;
 	default:
 		break;
Index: linux-2.6.23-rt1/arch/x86_64/kernel/kprobes.c
===================================================================
--- linux-2.6.23-rt1.orig/arch/x86_64/kernel/kprobes.c	2007-10-11 15:57:25.000000000 -0400
+++ linux-2.6.23-rt1/arch/x86_64/kernel/kprobes.c	2007-10-11 16:01:16.000000000 -0400
@@ -654,11 +654,9 @@ int __kprobes kprobe_exceptions_notify(s
 	case DIE_GPF:
 	case DIE_PAGE_FAULT:
 		/* kprobe_running() needs smp_processor_id() */
-		preempt_disable();
-		if (kprobe_running() &&
+		if (per_cpu(current_kprobe, raw_smp_processor_id()) &&
 		    kprobe_fault_handler(args->regs, args->trapnr))
 			ret = NOTIFY_STOP;
-		preempt_enable();
 		break;
 	default:
 		break;
Index: linux-2.6.23-rt1/include/linux/netpoll.h
===================================================================
--- linux-2.6.23-rt1.orig/include/linux/netpoll.h	2007-10-11 15:57:25.000000000 -0400
+++ linux-2.6.23-rt1/include/linux/netpoll.h	2007-10-11 16:01:16.000000000 -0400
@@ -69,7 +69,7 @@ static inline void *netpoll_poll_lock(st
 	rcu_read_lock(); /* deal with race on ->npinfo */
 	if (dev->npinfo) {
 		spin_lock(&dev->npinfo->poll_lock);
-		dev->npinfo->poll_owner = smp_processor_id();
+		dev->npinfo->poll_owner = raw_smp_processor_id();
 		return dev->npinfo;
 	}
 	return NULL;
Index: linux-2.6.23-rt1/kernel/hrtimer.c
===================================================================
--- linux-2.6.23-rt1.orig/kernel/hrtimer.c	2007-10-11 16:01:15.000000000 -0400
+++ linux-2.6.23-rt1/kernel/hrtimer.c	2007-10-11 16:01:16.000000000 -0400
@@ -1145,7 +1145,9 @@ void hrtimer_interrupt(struct clock_even
 
 static void run_hrtimer_softirq(struct softirq_action *h)
 {
-	struct hrtimer_cpu_base *cpu_base = &__get_cpu_var(hrtimer_bases);
+	struct hrtimer_cpu_base *cpu_base;
+
+	cpu_base = &per_cpu(hrtimer_bases, raw_smp_processor_id());
 
 	spin_lock_irq(&cpu_base->lock);
 
Index: linux-2.6.23-rt1/kernel/workqueue.c
===================================================================
--- linux-2.6.23-rt1.orig/kernel/workqueue.c	2007-10-11 16:01:04.000000000 -0400
+++ linux-2.6.23-rt1/kernel/workqueue.c	2007-10-11 16:01:16.000000000 -0400
@@ -182,7 +182,7 @@ void delayed_work_timer_fn(unsigned long
 	struct cpu_workqueue_struct *cwq = get_wq_data(&dwork->work);
 	struct workqueue_struct *wq = cwq->wq;
 
-	__queue_work(wq_per_cpu(wq, smp_processor_id()), &dwork->work);
+	__queue_work(wq_per_cpu(wq, raw_smp_processor_id()), &dwork->work);
 }
 
 /**
